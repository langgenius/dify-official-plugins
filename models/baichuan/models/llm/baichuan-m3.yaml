model: baichuan-m3
label:
  en_US: Baichuan-M3
model_type: llm
features:
  - agent-thought
  - multi-tool-call
model_properties:
  mode: chat
  context_size: 32000
parameter_rules:
  - name: temperature
    use_template: temperature
    default: 0.6
  - name: top_p
    use_template: top_p
    default: 0.95
  - name: top_k
    label:
      zh_Hans: 取样数量
      en_US: Top k
    type: int
    min: 0
    max: 20
    default: 5
    help:
      zh_Hans: 仅从每个后续标记的前 K 个选项中采样。
      en_US: Only sample from the top K options for each subsequent token.
    required: false
  - name: max_tokens
    use_template: max_tokens
    default: 8192
    min: 1
    max: 30000

