model: DeepSeek-V3
label:
  zh_Hans: DeepSeek-V3
  en_US: DeepSeek-V3
model_type: llm
features:
  - agent-thought
model_properties:
  mode: chat
  context_size: 32000
parameter_rules:
  - name: temperature
    use_template: temperature
    default: 0.6
  - name: top_p
    use_template: top_p
    default: 0.95
  - name: max_tokens
    use_template: max_tokens
    min: 1
    max: 16384
    default: 16384
  - name: response_format
    label:
      zh_Hans: 回复格式
      en_US: Response Format
    type: string
    help:
      zh_Hans: 指定模型必须输出的格式
      en_US: Specifies the format that the model must output
    required: false
    options:
      - text
      - json_object
pricing:
  input: "2"
  output: "8"
  unit: "0.000001"
  currency: RMB
