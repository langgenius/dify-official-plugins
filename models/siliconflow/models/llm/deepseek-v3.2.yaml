model: deepseek-ai/DeepSeek-V3.2
label:
  en_US: deepseek-ai/DeepSeek-V3.2
model_type: llm
features:
  - agent-thought
  - tool-call
  - stream-tool-call
  - multi-tool-call
  - document
  - structured-output
model_properties:
  mode: chat
  context_size: 163840
parameter_rules:
  - name: temperature
    type: float
    required: true
    default: 1
    min: 0
    max: 2
    label:
      en_US: Temperature
      zh_Hans: 温度
    help:
      en_US: For Gemini 3, best results at default 1.0. Lower values may impact reasoning.
      zh_Hans: 对于 Gemini 3，使用默认值 1.0 可获得最佳效果。数值过低可能会影响推理能力。
  - name: max_tokens
    use_template: max_tokens
    type: int
    default: 32768
    min: 1
    max: 65536
    help:
      zh_Hans: 指定生成结果长度的上限。如果生成结果截断，可以调大该参数。
      en_US: Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter.
  - name: response_format
    label:
      zh_Hans: 回复格式
      en_US: Response Format
    type: string
    help:
      zh_Hans: 指定模型必须输出的格式
      en_US: specifying the format that the model must output
    required: false
    options:
      - text
      - json_object
  - name: enable_thinking
    required: false
    type: boolean
    default: false
    label:
      zh_Hans: 思考模式
      en_US: Thinking mode
    help:
      zh_Hans: 是否开启思考模式。
      en_US: Whether to enable thinking mode.
pricing:
  input: "2"
  output: "3"
  unit: "0.000001"
  currency: RMB
