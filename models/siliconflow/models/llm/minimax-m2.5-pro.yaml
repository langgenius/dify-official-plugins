model: Pro/MiniMaxAI/MiniMax-M2.5
label:
  zh_Hans: Pro/MiniMaxAI/MiniMax-M2.5
  en_US: Pro/MiniMaxAI/MiniMax-M2.5
model_type: llm
features:
  - tool-call
  - multi-tool-call
  - agent-thought
  - stream-tool-call
model_properties:
  mode: chat
  context_size: 200000
parameter_rules:
  - name: temperature
    use_template: temperature
    type: float
    default: 1.0
    min: 0
    max: 2
  - name: max_tokens
    use_template: max_tokens
    type: int
    default: 16384
    min: 1
    max: 131072
    help:
      zh_Hans: 指定生成结果长度的上限。如果生成结果截断，可以调大该参数。
      en_US: Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter.
  - name: top_p
    use_template: top_p
    type: float
    default: 0.95
    min: 0.1
    max: 1.0
  - name: top_k
    label:
      zh_Hans: 取样数量
      en_US: Top k
    type: int
    default: 40
    min: 0
    max: 100
    help:
      zh_Hans: 仅从每个后续标记的前 K 个选项中采样。
      en_US: Only sample from the top K options for each subsequent token.
    required: false
  - name: frequency_penalty
    use_template: frequency_penalty
    type: float
    default: 0.0
    min: -2.0
    max: 2.0
  - name: thinking_budget
    required: false
    type: int
    default: 16384
    min: 1
    max: 98304
    label:
      zh_Hans: 思考长度限制
      en_US: Thinking budget
    help:
      zh_Hans: 思考过程的最大长度。
      en_US: The maximum length of the thinking process.
  - name: response_format
    label:
      zh_Hans: 回复格式
      en_US: Response Format
    type: string
    help:
      zh_Hans: 指定模型必须输出的格式
      en_US: specifying the format that the model must output
    required: false
    options:
      - text
      - json_object
pricing:
  input: '2.1'
  output: '8.4'
  unit: '0.000001'
  currency: RMB
