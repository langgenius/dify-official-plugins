model: mimo-v2-flash
label:
  zh_Hans: mimo-v2-flash
  en_US: mimo-v2-flash
model_type: llm
features:
  - multi-tool-call
  - agent-thought
  - stream-tool-call
model_properties:
  mode: chat
  context_size: 256000
parameter_rules:
  - name: temperature
    use_template: temperature
    type: float
    default: 0.8
    min: 0
    max: 1.5
    help:
      zh_Hans: 控制生成结果的多样性和随机性。数值越小，越严谨；数值越大，越发散。
      en_US: Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is.
  - name: top_p
    use_template: top_p
    type: float
    default: 0.95
    min: 0.01
    max: 1.00
    help:
      zh_Hans: 控制生成结果的随机性。数值越小，随机性越弱；数值越大，随机性越强。一般而言，top_p 和 temperature 两个参数选择一个进行调整即可。
      en_US: Control the randomness of generated results. The smaller the value, the weaker the randomness; the larger the value, the stronger the randomness. Generally speaking, you can adjust one of the two parameters top_p and temperature.
  - name: response_format
    label:
      zh_Hans: 回复格式
      en_US: Response Format
    type: string
    help:
      zh_Hans: 指定模型必须输出的格式
      en_US: specifying the format that the model must output
    required: false
    options:
      - text
      - json_object
  - name: thinking
    required: false
    type: string
    default: disabled
    label:
      zh_Hans: 思考模式
      en_US: Thinking mode
    help:
      zh_Hans: 是否开启思考模式。
      en_US: Whether to enable thinking mode.
    options:
      - enabled
      - disabled
pricing:
  input: "0"
  output: "0"
  unit: "1"
  currency: USD
