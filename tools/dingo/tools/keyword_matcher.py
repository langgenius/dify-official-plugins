"""
Keyword Matcher Tool for Dingo - ATS-Optimized Resume-JD Matching

Implements industry-standard TF-IDF weighted keyword matching algorithm used by 98% of Fortune 500 ATS systems.
Combines Resume-Matcher's frequency-based priority classification with LLM-powered optimization recommendations.

Algorithm:
1. Dual-Engine Extraction: Extract keywords from both resume and JD using keyword_extraction logic
2. TF-IDF Weighting: Calculate keyword importance based on frequency in JD
3. Priority Classification: High (â‰¥3 mentions), Medium (2 mentions), Low (1 mention)
4. Weighted Scoring: Calculate match score with priority-based weights
5. LLM Recommendations: Generate actionable optimization suggestions

Reference: 
- Resume-Matcher/apps/backend/app/services/score_improvement_service.py
- TF-IDF algorithm used by 98% Fortune 500 companies (LinkedIn, 2021)
"""

import re
import json
import time
from pathlib import Path
from typing import Any
from collections.abc import Generator

from dify_plugin import Tool
from dify_plugin.entities.tool import ToolInvokeMessage
from dify_plugin.entities.model.llm import LLMModelConfig
from dify_plugin.entities.model.message import UserPromptMessage

# Import TECH_SYNONYMS dictionary (not the class to avoid multiple Tool subclasses)
from .keyword_extraction import TECH_SYNONYMS


class KeywordMatcher(Tool):
    """
    ATS-Optimized Keyword Matcher: TF-IDF Weighted Matching + LLM Recommendations
    
    Implements the same algorithm used by major ATS systems (Taleo, Workday, Greenhouse)
    to calculate resume-job description match scores.
    """
    
    # Keywords that need case-sensitive matching
    CASE_SENSITIVE_KEYWORDS = {"Go", "R"}
    
    # Synonym mapping (same as keyword_extraction)
    SYNONYM_MAP = {
        "k8s": "Kubernetes",
        "js": "JavaScript",
        "ts": "TypeScript",
        "py": "Python",
        "tf": "TensorFlow",
        "react.js": "React",
        "vue.js": "Vue.js",
        "node.js": "Node.js",
        "next.js": "Next.js",
        "express.js": "Express.js",
        "nest.js": "NestJS",
        "postgresql": "PostgreSQL",
        "mysql": "MySQL",
        "mongodb": "MongoDB",
        "aws": "AWS",
        "gcp": "GCP",
        "ci/cd": "CI/CD",
        "ml": "Machine Learning",
        "ai": "Artificial Intelligence",
        "nlp": "Natural Language Processing",
        "cv": "Computer Vision",
    }
    
    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage]:
        try:
            resume_text = tool_parameters.get('resume_text', '').strip()
            resume_keywords_json = tool_parameters.get('resume_keywords', '').strip()
            jd_text = tool_parameters.get('jd_text', '').strip()
            position_name = tool_parameters.get('position_name', '').strip()
            use_llm = tool_parameters.get('use_llm', True)

            if not resume_text:
                yield self.create_text_message("âŒ Resume text cannot be empty")
                return

            # Must provide either jd_text or position_name
            if not jd_text and not position_name:
                yield self.create_text_message("âŒ å¿…é¡»æä¾› jd_textï¼ˆå®Œæ•´èŒä½æè¿°ï¼‰æˆ– position_nameï¼ˆèŒä½åç§°ï¼‰ä¹‹ä¸€")
                return

            # Load keyword dictionary
            current_dir = Path(__file__).parent.parent
            dictionary_path = current_dir / "data" / "onet_keywords.json"
            keywords = self._load_dictionary(dictionary_path)

            # 1. Get resume keywords (reuse if provided, otherwise extract)
            if resume_keywords_json:
                # Try to parse the input intelligently
                resume_keywords = self._parse_resume_keywords_input(resume_keywords_json)

                if resume_keywords is None:
                    # Parsing failed, extract from resume text instead
                    resume_keywords = self._extract_keywords_dual_engine(resume_text, use_llm, keywords)
            else:
                # Extract keywords from resume
                resume_keywords = self._extract_keywords_dual_engine(resume_text, use_llm, keywords)

            # 2. Get JD keywords: either from provided JD text or generate from position name
            if jd_text:
                # User provided full JD text
                jd_keywords = self._extract_keywords_dual_engine(jd_text, use_llm, keywords)
                jd_source = "ç”¨æˆ·æä¾›çš„èŒä½æè¿°"
            else:
                # User only provided position name, use LLM to generate standard requirements
                if not use_llm:
                    yield self.create_text_message("âŒ ä½¿ç”¨èŒä½åç§°ç”Ÿæˆæ ‡å‡†è¦æ±‚æ—¶ï¼Œå¿…é¡»å¯ç”¨ LLMï¼ˆuse_llm=trueï¼‰")
                    return

                generated_jd = self._generate_standard_jd_requirements(position_name)
                jd_keywords = self._extract_keywords_from_generated_jd(generated_jd)
                jd_source = f"LLM ç”Ÿæˆçš„æ ‡å‡†èŒä½è¦æ±‚ï¼ˆ{position_name}ï¼‰"
                # Use generated JD as jd_text for display
                jd_text = generated_jd

            # 3. Perform matching analysis
            match_result = self._calculate_match_score(
                resume_keywords, jd_keywords, resume_text, jd_text, use_llm, jd_source
            )

            # Create summary text
            summary = self._create_summary(match_result, True)

            # Yield results
            json_message = self.create_json_message(match_result)
            text_message = self.create_text_message(summary)
            yield from [json_message, text_message]

        except Exception as e:
            yield self.create_text_message(f"âŒ Keyword matching failed: {str(e)}")
    
    def _load_dictionary(self, dictionary_path: Path) -> list[str]:
        """Load O*NET keyword dictionary"""
        with open(dictionary_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        all_keywords = []
        for category_keywords in data['keywords'].values():
            all_keywords.extend(category_keywords)
        
        return all_keywords
    
    def _normalize_synonyms(self, text: str) -> str:
        """Normalize synonyms (K8sâ†’Kubernetes, etc.)"""
        normalized = text
        for synonym, standard in self.SYNONYM_MAP.items():
            pattern = re.compile(rf'\b{re.escape(synonym)}\b', re.IGNORECASE)
            normalized = pattern.sub(standard, normalized)
        return normalized
    
    def _prepare_text_for_matching(self, text: str) -> str:
        """
        Prepare text for keyword matching (Resume-Matcher pattern)
        Remove markdown symbols but preserve technical terms like C#, C++
        """
        lowered = text.lower()
        lowered = re.sub(r"[`*_>\-]", " ", lowered)
        lowered = re.sub(r"(?<![a-z])#(?![a-z])", " ", lowered)
        lowered = re.sub(r"\s+", " ", lowered)
        return lowered
    
    def _count_mentions(self, keyword: str, text: str) -> tuple[int, str]:
        """
        Count keyword mentions in text, including synonyms.

        Returns:
            (count, match_type):
            - count: Total mentions (exact + synonyms)
            - match_type: "exact" | "synonym:{matched_synonym}" | "none"
        """
        text_lower = text.lower()
        keyword_lower = keyword.lower()

        # 1. Exact match (case-insensitive for most keywords)
        if keyword in self.CASE_SENSITIVE_KEYWORDS:
            pattern = re.compile(rf"(?<!\w){re.escape(keyword)}(?!\w)")
            exact_count = len(pattern.findall(text))
        else:
            text_normalized = self._prepare_text_for_matching(text)
            pattern = re.compile(rf"(?<!\w){re.escape(keyword_lower)}(?!\w)")
            exact_count = len(pattern.findall(text_normalized))

        if exact_count > 0:
            return exact_count, "exact"

        # 2. Synonym match
        synonyms = TECH_SYNONYMS.get(keyword, [])
        synonym_count = 0
        matched_synonym = None

        for synonym in synonyms:
            synonym_lower = synonym.lower()
            # Use word boundary regex for synonym matching
            pattern = re.compile(rf"(?<!\w){re.escape(synonym_lower)}(?!\w)")
            count = len(pattern.findall(text_lower))
            if count > 0:
                synonym_count += count
                if matched_synonym is None:
                    matched_synonym = synonym

        if synonym_count > 0:
            return synonym_count, f"synonym:{matched_synonym}"

        # 3. No match
        return 0, "none"

    def _extract_with_dictionary(self, text: str, keywords: list[str]) -> list[dict[str, Any]]:
        """Extract keywords using dictionary matching (Engine 1)"""
        text_normalized = self._normalize_synonyms(text)
        text_norm = self._prepare_text_for_matching(text_normalized)

        results = []
        for keyword in keywords:
            if keyword in self.CASE_SENSITIVE_KEYWORDS:
                pattern = re.compile(rf"(?<!\w){re.escape(keyword)}(?!\w)")
                mentions = len(pattern.findall(text_normalized))
            else:
                kw_lower = keyword.lower()
                pattern = re.compile(rf"(?<!\w){re.escape(kw_lower)}(?!\w)")
                mentions = len(pattern.findall(text_norm))

            if mentions > 0:
                results.append({
                    "skill": keyword,
                    "mentions": mentions,
                    "confidence": 1.0,
                    "source": "dictionary"
                })

        return results

    def _extract_with_llm(self, text: str) -> list[dict[str, Any]]:
        """Extract keywords using LLM semantic analysis (Engine 2)"""
        prompt = f"""You are a technical keyword extraction expert. Extract ALL technology keywords from this text.

Output ONLY valid JSON (no markdown, no code blocks):
{{
  "keywords": [
    {{"skill": "Python", "confidence": 1.0, "source": "explicit"}},
    {{"skill": "Docker", "confidence": 0.85, "source": "inferred"}}
  ]
}}

Text:
{text}"""

        llm_config = {
            "provider": "deepseek",
            "model": "deepseek-chat",
            "mode": "chat",
            "completion_params": {
                "temperature": 0.3,
                "max_tokens": 2000
            }
        }

        # Retry logic for LLM invocation
        max_retries = 3
        retry_delay = 1  # Initial delay in seconds

        for attempt in range(max_retries):
            try:
                llm_result = self.session.model.llm.invoke(
                    model_config=LLMModelConfig(**llm_config),
                    prompt_messages=[UserPromptMessage(content=prompt)],
                    stream=False
                )

                response_text = llm_result.message.content.strip()

                # Check for empty response
                if not response_text:
                    if attempt < max_retries - 1:
                        print(f"âš ï¸ LLM returned empty response (attempt {attempt + 1}/{max_retries}), retrying in {retry_delay}s...")
                        time.sleep(retry_delay)
                        retry_delay *= 2
                        continue
                    else:
                        print(f"âŒ LLM returned empty response after {max_retries} attempts")
                        return []

                # Clean markdown code blocks
                response_text = re.sub(r'^```json\s*', '', response_text)
                response_text = re.sub(r'\s*```$', '', response_text)

                llm_data = json.loads(response_text)
                keywords = llm_data.get('keywords', [])

                if keywords:
                    return keywords
                else:
                    if attempt < max_retries - 1:
                        print(f"âš ï¸ LLM returned empty keywords list (attempt {attempt + 1}/{max_retries}), retrying in {retry_delay}s...")
                        time.sleep(retry_delay)
                        retry_delay *= 2
                        continue
                    else:
                        return []

            except json.JSONDecodeError as json_err:
                if attempt < max_retries - 1:
                    print(f"âš ï¸ JSON parsing failed (attempt {attempt + 1}/{max_retries}): {str(json_err)}, retrying in {retry_delay}s...")
                    time.sleep(retry_delay)
                    retry_delay *= 2
                    continue
                else:
                    print(f"âŒ JSON parsing failed after {max_retries} attempts: {str(json_err)}")
                    return []

            except Exception as llm_err:
                if attempt < max_retries - 1:
                    print(f"âš ï¸ LLM invocation failed (attempt {attempt + 1}/{max_retries}): {str(llm_err)}, retrying in {retry_delay}s...")
                    time.sleep(retry_delay)
                    retry_delay *= 2
                    continue
                else:
                    print(f"âŒ LLM invocation failed after {max_retries} attempts: {str(llm_err)}")
                    return []

        return []

    def _merge_keywords(self, dict_results: list[dict], llm_results: list[dict]) -> list[dict]:
        """Merge and deduplicate keywords from both engines"""
        merged = {}

        for kw in dict_results:
            skill = kw['skill']
            merged[skill] = kw

        for kw in llm_results:
            skill = kw['skill']
            if skill not in merged:
                merged[skill] = kw
            else:
                merged[skill]['confidence'] = max(merged[skill]['confidence'], kw.get('confidence', 0.7))

        return list(merged.values())

    def _extract_keywords_dual_engine(self, text: str, use_llm: bool, keywords: list[str]) -> list[dict]:
        """Extract keywords using dual-engine architecture"""
        dict_results = self._extract_with_dictionary(text, keywords)

        if use_llm:
            llm_results = self._extract_with_llm(text)
            return self._merge_keywords(dict_results, llm_results)
        else:
            return dict_results

    def _analyze_jd_priority_with_llm(self, jd_text: str, jd_keywords: list[str], use_llm: bool) -> dict:
        """
        Analyze JD and classify keywords into Must-have/High/Medium/Nice-to-have
        using LLM (simulating Greenhouse/Lever ATS logic)

        Args:
            jd_text: Job description text
            jd_keywords: List of extracted keywords
            use_llm: Whether to use LLM for analysis

        Returns:
            Dictionary with classified keywords:
            {
                "must_have": [...],
                "high_priority": [...],
                "medium_priority": [...],
                "nice_to_have": [...],
                "reasoning": "..."
            }
        """
        if not use_llm or not jd_keywords:
            # Fallback: use frequency-based classification
            return self._fallback_priority_classification(jd_text, jd_keywords)

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ‹›è˜ ATS ç³»ç»Ÿåˆ†æä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹èŒä½æè¿°ï¼ˆJDï¼‰ï¼Œå°†æå–çš„å…³é”®è¯æŒ‰ç…§ Greenhouse/Lever ATS ç³»ç»Ÿçš„æ ‡å‡†åˆ†ç±»ã€‚

## èŒä½æè¿°

{jd_text}

## å·²æå–çš„å…³é”®è¯

{', '.join(jd_keywords)}

## åˆ†ç±»æ ‡å‡†

**Must-haveï¼ˆå¿…éœ€æŠ€èƒ½ï¼‰**ï¼š
- å‡ºç°åœ¨"ä»»èŒè¦æ±‚"/"Required Qualifications"éƒ¨åˆ†
- ä½¿ç”¨"å¿…é¡»"/"must"/"required"ç­‰å¼ºåˆ¶æ€§è¯æ±‡
- æ˜¯å²—ä½çš„æ ¸å¿ƒæŠ€èƒ½ï¼Œç¼ºå¤±åˆ™æ— æ³•èƒœä»»
- ç¤ºä¾‹ï¼šå¯¹äºç®—æ³•å·¥ç¨‹å¸ˆï¼Œ"Python"å’Œ"æœºå™¨å­¦ä¹ "é€šå¸¸æ˜¯ Must-have

**High Priorityï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰**ï¼š
- å‡ºç°åœ¨"æ ¸å¿ƒæŠ€èƒ½"/"Key Skills"éƒ¨åˆ†
- JD ä¸­å¤šæ¬¡å¼ºè°ƒï¼ˆå‡ºç° 3 æ¬¡ä»¥ä¸Šï¼‰
- æ˜¯å²—ä½çš„ä¸»è¦å·¥ä½œå†…å®¹æ‰€éœ€æŠ€èƒ½
- ç¤ºä¾‹ï¼šå¯¹äºç®—æ³•å·¥ç¨‹å¸ˆï¼Œ"TensorFlow"æˆ–"PyTorch"é€šå¸¸æ˜¯ High Priority

**Medium Priorityï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰**ï¼š
- å‡ºç°åœ¨"ä¼˜å…ˆæ¡ä»¶"/"Preferred Qualifications"éƒ¨åˆ†
- JD ä¸­æåŠ 2 æ¬¡å·¦å³
- æ˜¯åŠ åˆ†é¡¹ï¼Œä½†ä¸æ˜¯å¿…éœ€
- ç¤ºä¾‹ï¼šå¯¹äºç®—æ³•å·¥ç¨‹å¸ˆï¼Œ"Docker"å’Œ"Kubernetes"é€šå¸¸æ˜¯ Medium Priority

**Nice-to-haveï¼ˆåŠ åˆ†é¡¹ï¼‰**ï¼š
- å‡ºç°åœ¨"åŠ åˆ†é¡¹"/"Nice to have"éƒ¨åˆ†
- JD ä¸­åªæåŠ 1 æ¬¡
- æ˜¯é”¦ä¸Šæ·»èŠ±çš„æŠ€èƒ½
- ç¤ºä¾‹ï¼šå¯¹äºç®—æ³•å·¥ç¨‹å¸ˆï¼Œ"AWS"å’Œ"GCP"é€šå¸¸æ˜¯ Nice-to-have

## è¾“å‡ºæ ¼å¼ï¼ˆJSON onlyï¼‰

{{
  "must_have": ["Python", "Machine Learning"],
  "high_priority": ["TensorFlow", "PyTorch", "Deep Learning"],
  "medium_priority": ["Docker", "Kubernetes", "Linux"],
  "nice_to_have": ["AWS", "GCP", "CI/CD"],
  "reasoning": "ç®€è¦è¯´æ˜åˆ†ç±»ä¾æ®"
}}

**é‡è¦**ï¼š
1. æ¯ä¸ªå…³é”®è¯åªèƒ½å‡ºç°åœ¨ä¸€ä¸ªåˆ†ç±»ä¸­
2. å¦‚æœ JD æ²¡æœ‰æ˜ç¡®åŒºåˆ†ï¼Œæ ¹æ®å²—ä½ç±»å‹å’Œè¡Œä¸šæƒ¯ä¾‹åˆ¤æ–­
3. Must-have é€šå¸¸ä¸è¶…è¿‡ 3-5 ä¸ªå…³é”®è¯
4. è¾“å‡º ONLY valid JSONï¼Œno markdown"""

        try:
            # Invoke LLM with retry logic
            max_retries = 3
            retry_delay = 1

            for attempt in range(max_retries):
                try:
                    llm_result = self.session.model.llm.invoke(
                        model_config=LLMModelConfig(**self.runtime.credentials),
                        prompt_messages=[UserPromptMessage(content=prompt)],
                        stream=False
                    )

                    if llm_result and hasattr(llm_result, 'message') and hasattr(llm_result.message, 'content'):
                        response_text = llm_result.message.content.strip()

                        if not response_text:
                            if attempt < max_retries - 1:
                                time.sleep(retry_delay)
                                retry_delay *= 2
                                continue
                            else:
                                return self._fallback_priority_classification(jd_text, jd_keywords)

                        # Parse JSON
                        # Remove markdown code blocks if present
                        if "```json" in response_text:
                            response_text = response_text.split("```json")[1].split("```")[0].strip()
                        elif "```" in response_text:
                            response_text = response_text.split("```")[1].split("```")[0].strip()

                        priority_analysis = json.loads(response_text)

                        # Validate structure
                        required_keys = ["must_have", "high_priority", "medium_priority", "nice_to_have"]
                        if all(key in priority_analysis for key in required_keys):
                            return priority_analysis
                        else:
                            return self._fallback_priority_classification(jd_text, jd_keywords)

                except json.JSONDecodeError:
                    if attempt < max_retries - 1:
                        time.sleep(retry_delay)
                        retry_delay *= 2
                        continue
                    else:
                        return self._fallback_priority_classification(jd_text, jd_keywords)

                except Exception:
                    if attempt < max_retries - 1:
                        time.sleep(retry_delay)
                        retry_delay *= 2
                        continue
                    else:
                        return self._fallback_priority_classification(jd_text, jd_keywords)

            return self._fallback_priority_classification(jd_text, jd_keywords)

        except Exception:
            return self._fallback_priority_classification(jd_text, jd_keywords)

    def _fallback_priority_classification(self, jd_text: str, jd_keywords: list[str]) -> dict:
        """
        Fallback priority classification based on keyword frequency in JD
        (used when LLM is unavailable or fails)
        """
        result = {
            "must_have": [],
            "high_priority": [],
            "medium_priority": [],
            "nice_to_have": [],
            "reasoning": "åŸºäºå…³é”®è¯åœ¨ JD ä¸­çš„å‡ºç°é¢‘ç‡è‡ªåŠ¨åˆ†ç±»ï¼ˆLLM ä¸å¯ç”¨ï¼‰"
        }

        for keyword in jd_keywords:
            count, _ = self._count_mentions(keyword, jd_text)

            if count >= 3:
                result["high_priority"].append(keyword)
            elif count == 2:
                result["medium_priority"].append(keyword)
            else:
                result["nice_to_have"].append(keyword)

        # If no must_have, promote top 2-3 high_priority to must_have
        if not result["must_have"] and result["high_priority"]:
            result["must_have"] = result["high_priority"][:min(3, len(result["high_priority"]))]
            result["high_priority"] = result["high_priority"][min(3, len(result["high_priority"])):]

        return result

    def _build_skill_comparison(self, resume_keywords: list[dict], jd_keywords: list[dict],
                                resume_text: str, jd_text: str) -> list[dict]:
        """
        Build skill comparison statistics (Resume-Matcher algorithm)

        For each JD keyword, count mentions in both resume and JD to calculate:
        - Priority (based on JD frequency)
        - Weight (TF-IDF inspired)
        - Match status
        - Match type (exact or synonym)
        """
        jd_skills = {kw['skill'] for kw in jd_keywords}
        resume_skills = {kw['skill'] for kw in resume_keywords}

        stats = []
        for jd_kw in jd_keywords:
            skill = jd_kw['skill']

            # Count mentions in both texts (with synonym support)
            jd_mentions, _ = self._count_mentions(skill, jd_text)
            resume_mentions, match_type = self._count_mentions(skill, resume_text)

            # Priority classification (Resume-Matcher pattern)
            if jd_mentions >= 3:
                priority = "high"
                weight = 3.0
            elif jd_mentions == 2:
                priority = "medium"
                weight = 2.0
            else:
                priority = "low"
                weight = 1.0

            stats.append({
                "skill": skill,
                "resume_mentions": resume_mentions,
                "jd_mentions": jd_mentions,
                "priority": priority,
                "weight": weight,
                "matched": resume_mentions > 0,
                "match_type": match_type  # "exact" | "synonym:xxx" | "none"
            })

        return stats

    def _calculate_match_score(self, resume_keywords: list[dict], jd_keywords: list[dict],
                               resume_text: str, jd_text: str, use_llm: bool, jd_source: str = "ç”¨æˆ·æä¾›çš„èŒä½æè¿°") -> dict:
        """
        Calculate ATS match score simulating Greenhouse/Lever logic

        New algorithm (v0.5.0):
        1. Use LLM to classify JD keywords into Must-have/High/Medium/Nice-to-have
        2. Match keywords with synonym support
        3. Calculate Greenhouse-style score with tiered weighting
        4. Generate actionable optimization suggestions

        Args:
            resume_keywords: Extracted resume keywords
            jd_keywords: Extracted JD keywords
            resume_text: Original resume text
            jd_text: Original JD text
            use_llm: Whether to use LLM for analysis
            jd_source: Source of JD keywords (for display purposes)

        Returns comprehensive match analysis with:
        - Greenhouse score (simulated)
        - Tiered match rates (Must-have/High/Medium/Nice-to-have)
        - Match type details (exact vs synonym)
        - Optimization suggestions
        """
        # 1. Analyze JD priority with LLM
        jd_keyword_list = [kw['skill'] for kw in jd_keywords]
        priority_analysis = self._analyze_jd_priority_with_llm(jd_text, jd_keyword_list, use_llm)

        # 2. Match keywords for each priority level
        match_results = {
            "must_have": [],
            "high_priority": [],
            "medium_priority": [],
            "nice_to_have": []
        }

        for priority_level, keywords in priority_analysis.items():
            if priority_level == "reasoning":
                continue

            for keyword in keywords:
                count, match_type = self._count_mentions(keyword, resume_text)

                match_results[priority_level].append({
                    "skill": keyword,
                    "matched": count > 0,
                    "match_type": match_type,
                    "mentions": count
                })

        # 3. Calculate tiered match rates
        must_have_total = len(match_results["must_have"])
        must_have_matched = sum(1 for s in match_results["must_have"] if s["matched"])
        must_have_rate = (must_have_matched / must_have_total * 100) if must_have_total > 0 else 100

        high_total = len(match_results["high_priority"])
        high_matched = sum(1 for s in match_results["high_priority"] if s["matched"])
        high_rate = (high_matched / high_total * 100) if high_total > 0 else 100

        medium_total = len(match_results["medium_priority"])
        medium_matched = sum(1 for s in match_results["medium_priority"] if s["matched"])
        medium_rate = (medium_matched / medium_total * 100) if medium_total > 0 else 100

        nice_total = len(match_results["nice_to_have"])
        nice_matched = sum(1 for s in match_results["nice_to_have"] if s["matched"])
        nice_rate = (nice_matched / nice_total * 100) if nice_total > 0 else 100

        # 4. Check Must-have (must be 100% matched)
        if must_have_rate < 100:
            status = "rejected"
            greenhouse_score = 0
            recommendation = "âŒ ä¸æ¨èæŠ•é€’ï¼šç¼ºå¤±å¿…éœ€æŠ€èƒ½"
        else:
            # 5. Calculate Greenhouse score (weighted)
            greenhouse_score = (
                must_have_rate * 0.4 +   # Must-have: 40%
                high_rate * 0.3 +         # High Priority: 30%
                medium_rate * 0.2 +       # Medium Priority: 20%
                nice_rate * 0.1           # Nice-to-have: 10%
            )

            # 6. Determine status
            if greenhouse_score >= 85:
                status = "strongly_recommended"
                recommendation = "âœ… å¼ºçƒˆæ¨èæŠ•é€’ï¼šç®€å†é«˜åº¦åŒ¹é…"
            elif greenhouse_score >= 75:
                status = "recommended"
                recommendation = "âœ… æ¨èæŠ•é€’ï¼šç®€å†åŒ¹é…åº¦è‰¯å¥½"
            elif greenhouse_score >= 65:
                status = "consider"
                recommendation = "âš ï¸ å¯ä»¥è€ƒè™‘ï¼šå»ºè®®ä¼˜åŒ–åæŠ•é€’"
            else:
                status = "not_recommended"
                recommendation = "âŒ ä¸æ¨èæŠ•é€’ï¼šåŒ¹é…åº¦è¾ƒä½"

        # 7. Generate optimization suggestions
        optimization_suggestions = self._generate_optimization_suggestions(match_results, priority_analysis)

        # 8. Calculate legacy scores for comparison
        stats = self._build_skill_comparison(resume_keywords, jd_keywords, resume_text, jd_text)
        total_weight = sum(s['weight'] for s in stats)
        matched_weight = sum(s['weight'] for s in stats if s['matched'])
        legacy_weighted_score = round((matched_weight / total_weight * 100) if total_weight > 0 else 0, 1)

        total_keywords = len(stats)
        matched_keywords = sum(1 for s in stats if s['matched'])
        simple_score = round((matched_keywords / total_keywords * 100) if total_keywords > 0 else 0, 1)

        return {
            "greenhouse_analysis": {
                "greenhouse_score": round(greenhouse_score, 1),
                "status": status,
                "recommendation": recommendation,
                "must_have_match": f"{must_have_matched}/{must_have_total}",
                "must_have_rate": round(must_have_rate, 1),
                "high_priority_match": f"{high_matched}/{high_total}",
                "high_priority_rate": round(high_rate, 1),
                "medium_priority_match": f"{medium_matched}/{medium_total}",
                "medium_priority_rate": round(medium_rate, 1),
                "nice_to_have_match": f"{nice_matched}/{nice_total}",
                "nice_to_have_rate": round(nice_rate, 1)
            },
            "match_details": match_results,
            "priority_analysis": priority_analysis,
            "optimization_suggestions": optimization_suggestions,
            "legacy_scores": {
                "weighted_score": legacy_weighted_score,
                "simple_score": simple_score,
                "total_keywords": total_keywords,
                "matched_keywords": matched_keywords
            }
        }

    def _generate_optimization_suggestions(self, match_results: dict, priority_analysis: dict) -> str:
        """
        Generate actionable optimization suggestions based on match results

        Suggestions are prioritized by:
        1. Must-have missing (critical)
        2. Synonym matches (easy fix)
        3. High priority missing (important)
        4. Medium priority missing (recommended)
        """
        suggestions = []

        # 1. Must-have missing (highest priority)
        must_have_missing = [s for s in match_results["must_have"] if not s["matched"]]
        if must_have_missing:
            suggestions.append("## ğŸ”´ å¿…éœ€æŠ€èƒ½ç¼ºå¤±ï¼ˆå¿…é¡»è¡¥å……ï¼‰\n")
            for skill in must_have_missing:
                suggestions.append(f"- **{skill['skill']}**: è¿™æ˜¯å¿…éœ€æŠ€èƒ½ï¼Œç¼ºå¤±ä¼šç›´æ¥å¯¼è‡´ç®€å†è¢« ATS æ·˜æ±°")
                suggestions.append(f"  - å»ºè®®ï¼šå¦‚æœæœ‰ç›¸å…³ç»éªŒï¼Œè¯·åœ¨ç®€å†ä¸­æ˜ç¡®æ·»åŠ æ­¤å…³é”®è¯")
                suggestions.append(f"  - å»ºè®®ï¼šå¦‚æœæ²¡æœ‰ç»éªŒï¼Œå»ºè®®å…ˆå­¦ä¹ åå†æŠ•é€’\n")

        # 2. Synonym matches (easy fix - just change wording)
        synonym_matches = []
        for priority_level, skills in match_results.items():
            for skill in skills:
                if skill["matched"] and "synonym:" in skill["match_type"]:
                    synonym = skill["match_type"].split(":")[1]
                    synonym_matches.append((skill["skill"], synonym, priority_level))

        if synonym_matches:
            suggestions.append("## âš ï¸ ç”¨è¯ä¼˜åŒ–ï¼ˆæé«˜ ATS è¯†åˆ«ç‡ï¼‰\n")
            suggestions.append("**é—®é¢˜**ï¼šä½ ä½¿ç”¨äº†åŒä¹‰è¯æˆ–ç¼©å†™ï¼ŒATS ç³»ç»Ÿå¯èƒ½è¯†åˆ«ä¸å‡º\n")
            for standard, synonym, level in synonym_matches:
                suggestions.append(f"- ä½ å†™çš„æ˜¯ **{synonym}**ï¼Œå»ºè®®æ”¹ä¸º **{standard}**")
                suggestions.append(f"  - åŸå› ï¼šGreenhouse/Lever ç­‰ ATS ç³»ç»Ÿå¯èƒ½è¯†åˆ«ä¸å‡ºç¼©å†™æˆ–åŒä¹‰è¯")
                suggestions.append(f"  - å»ºè®®ï¼šæ”¹ä¸º '{standard} ({synonym})' æˆ–ç›´æ¥ç”¨ '{standard}'")
                suggestions.append(f"  - ä¼˜å…ˆçº§ï¼š{level}\n")

        # 3. High priority missing
        high_missing = [s for s in match_results["high_priority"] if not s["matched"]]
        if high_missing:
            suggestions.append("## ğŸŸ¡ é«˜ä¼˜å…ˆçº§æŠ€èƒ½ç¼ºå¤±ï¼ˆå¼ºçƒˆå»ºè®®è¡¥å……ï¼‰\n")
            for skill in high_missing:
                suggestions.append(f"- **{skill['skill']}**: é«˜ä¼˜å…ˆçº§æŠ€èƒ½ï¼Œè¡¥å……åå¯æ˜¾è‘—æå‡åŒ¹é…åº¦")
                suggestions.append(f"  - å»ºè®®ï¼šå¦‚æœæœ‰ç›¸å…³ç»éªŒï¼Œè¯·åœ¨é¡¹ç›®æè¿°ä¸­æ˜ç¡®æåŠ")
                suggestions.append(f"  - å»ºè®®ï¼šå¦‚æœæ²¡æœ‰ç»éªŒï¼Œè€ƒè™‘é€šè¿‡é¡¹ç›®æˆ–å­¦ä¹ è¡¥å……\n")

        # 4. Medium priority missing (only show top 3)
        medium_missing = [s for s in match_results["medium_priority"] if not s["matched"]]
        if medium_missing:
            suggestions.append("## ğŸŸ¢ ä¸­ä¼˜å…ˆçº§æŠ€èƒ½ç¼ºå¤±ï¼ˆå»ºè®®è¡¥å……ï¼‰\n")
            for skill in medium_missing[:3]:  # Only show top 3
                suggestions.append(f"- **{skill['skill']}**: ä¸­ä¼˜å…ˆçº§æŠ€èƒ½ï¼Œè¡¥å……åå¯æå‡ç«äº‰åŠ›\n")
            if len(medium_missing) > 3:
                suggestions.append(f"\n...è¿˜æœ‰ {len(medium_missing) - 3} ä¸ªä¸­ä¼˜å…ˆçº§æŠ€èƒ½ç¼ºå¤±\n")

        # 5. Summary
        if not must_have_missing:
            suggestions.append("## âœ… æ€»ç»“\n")
            if synonym_matches:
                suggestions.append(f"- ä½ å·²æ»¡è¶³æ‰€æœ‰å¿…éœ€æŠ€èƒ½ï¼Œä½†æœ‰ {len(synonym_matches)} ä¸ªå…³é”®è¯ä½¿ç”¨äº†åŒä¹‰è¯")
                suggestions.append(f"- å»ºè®®ä¼˜å…ˆä¿®æ”¹ç”¨è¯ï¼Œæé«˜ ATS è¯†åˆ«ç‡\n")
            if high_missing:
                suggestions.append(f"- ç¼ºå¤± {len(high_missing)} ä¸ªé«˜ä¼˜å…ˆçº§æŠ€èƒ½ï¼Œå»ºè®®è¡¥å……\n")
            if not synonym_matches and not high_missing:
                suggestions.append("- ä½ çš„ç®€å†åŒ¹é…åº¦å¾ˆé«˜ï¼Œå¯ä»¥ç›´æ¥æŠ•é€’ï¼\n")

        return "\n".join(suggestions) if suggestions else "æš‚æ— ä¼˜åŒ–å»ºè®®"

    def _generate_recommendations(self, resume_text: str, jd_text: str,
                                  matched: list[dict], missing: list[dict],
                                  missing_high: list[dict], missing_medium: list[dict],
                                  weighted_score: float) -> str:
        """Generate LLM-powered optimization recommendations"""

        matched_skills = ", ".join([s['skill'] for s in matched[:15]])
        missing_high_skills = ", ".join([s['skill'] for s in missing_high])
        missing_medium_skills = ", ".join([s['skill'] for s in missing_medium])

        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç®€å†ä¼˜åŒ–ä¸“å®¶å’Œ ATS ç³»ç»Ÿä¸“å®¶ã€‚åŸºäºå…³é”®è¯åŒ¹é…åˆ†æï¼Œç›´æ¥ç»™å‡ºå…·ä½“çš„ç®€å†ä¼˜åŒ–å»ºè®®ã€‚

## åŒ¹é…åˆ†æç»“æœ
- **ATS åŒ¹é…åº¦**: {weighted_score}%
- **å·²åŒ¹é…å…³é”®è¯**: {matched_skills}
- **ç¼ºå¤±å…³é”®è¯ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰**: {missing_high_skills or "æ— "}
- **ç¼ºå¤±å…³é”®è¯ï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰**: {missing_medium_skills or "æ— "}

## ç®€å†å†…å®¹
{resume_text[:2000]}

## èŒä½æè¿°
{jd_text[:2000]}

## è¾“å‡ºè¦æ±‚

**ä¸è¦**è‡ªæˆ‘ä»‹ç»ã€ä¸è¦åˆ†æé—®é¢˜ã€ä¸è¦ä»‹ç»å·¥ä½œè®¡åˆ’ï¼Œ**ç›´æ¥å¼€å§‹è¾“å‡ºä¼˜åŒ–å»ºè®®**ã€‚

æ¯æ¡å»ºè®®å¿…é¡»åŒ…å«ï¼š
- **æ”¹å‰**ï¼šä»ç®€å†ä¸­æ‘˜å½•éœ€è¦ä¿®æ”¹çš„åŸæ–‡ï¼ˆå¦‚æœæ˜¯æ–°å¢å†…å®¹ï¼Œå†™"æ— "ï¼‰
- **æ”¹å**ï¼šä¼˜åŒ–åçš„è¡¨è¿°ï¼ˆå¯ç›´æ¥å¤åˆ¶ç²˜è´´ä½¿ç”¨ï¼‰
- **ä¼˜åŒ–ç†ç”±**ï¼š1-2 å¥è¯è¯´æ˜ä¸ºä»€ä¹ˆè¿™æ ·æ”¹ï¼Œé‡ç‚¹è¯´æ˜å¦‚ä½•æå‡ ATS åŒ¹é…åº¦

**é‡è¦**ï¼šå¦‚æœæŸä¸ªä¼˜å…ˆçº§æ²¡æœ‰ä¼˜åŒ–å»ºè®®ï¼ˆä¾‹å¦‚ç¼ºå¤±å…³é”®è¯ä¸º"æ— "æˆ–ç®€å†å·²ç»å¾ˆå¥½ï¼‰ï¼Œ**ç›´æ¥è·³è¿‡è¯¥éƒ¨åˆ†**ï¼Œä¸è¦è¾“å‡º"æ”¹å‰ï¼šï¼ˆæ— ï¼‰æ”¹åï¼šï¼ˆæ— ï¼‰"è¿™æ ·çš„ç©ºå†…å®¹ã€‚

## è¾“å‡ºæ ¼å¼

### ğŸ”´ é«˜ä¼˜å…ˆçº§ä¼˜åŒ–ï¼ˆå¿…é¡»è¡¥å……ï¼‰

**ä»…åœ¨æœ‰ç¼ºå¤±çš„é«˜ä¼˜å…ˆçº§å…³é”®è¯æ—¶è¾“å‡ºæ­¤éƒ¨åˆ†**

**æ”¹å‰**ï¼š
```
[ä»ç®€å†ä¸­æ‘˜å½•çš„åŸæ–‡ï¼Œå¦‚æœæ˜¯æ–°å¢å†…å®¹åˆ™å†™"æ— "]
```

**æ”¹å**ï¼š
```
[ä¼˜åŒ–åçš„è¡¨è¿°ï¼ŒåŒ…å«ç¼ºå¤±çš„é«˜ä¼˜å…ˆçº§å…³é”®è¯]
```

**ä¼˜åŒ–ç†ç”±**ï¼š[è¯´æ˜å¦‚ä½•æå‡ ATS åŒ¹é…åº¦]

---

### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ä¼˜åŒ–ï¼ˆå»ºè®®è¡¥å……ï¼‰

**ä»…åœ¨æœ‰ç¼ºå¤±çš„ä¸­ä¼˜å…ˆçº§å…³é”®è¯æ—¶è¾“å‡ºæ­¤éƒ¨åˆ†**

**æ”¹å‰**ï¼š
```
[åŸæ–‡æˆ–"æ— "]
```

**æ”¹å**ï¼š
```
[ä¼˜åŒ–åçš„è¡¨è¿°ï¼ŒåŒ…å«ç¼ºå¤±çš„ä¸­ä¼˜å…ˆçº§å…³é”®è¯]
```

**ä¼˜åŒ–ç†ç”±**ï¼š[è¯´æ˜å¦‚ä½•æå‡ ATS åŒ¹é…åº¦]

---

### ğŸŸ¢ å·²åŒ¹é…å…³é”®è¯ä¼˜åŒ–ï¼ˆå¼ºåŒ–è¡¨è¿°ï¼‰

**ä»…åœ¨å·²åŒ¹é…å…³é”®è¯å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–æ—¶è¾“å‡ºæ­¤éƒ¨åˆ†**

**æ”¹å‰**ï¼š
```
[åŸæ–‡]
```

**æ”¹å**ï¼š
```
[ä¼˜åŒ–åçš„è¡¨è¿°ï¼Œå¢åŠ å…³é”®è¯å¯†åº¦æˆ–é‡åŒ–æŒ‡æ ‡]
```

**ä¼˜åŒ–ç†ç”±**ï¼š[è¯´æ˜å¦‚ä½•æ›´å¥½åœ°çªå‡ºå·²åŒ¹é…å…³é”®è¯]

---

## ä¼˜åŒ–é‡ç‚¹

1. **è¡¥å……ç¼ºå¤±å…³é”®è¯**ï¼šä¼˜å…ˆè¡¥å……é«˜ä¼˜å…ˆçº§å…³é”®è¯ï¼ˆ{missing_high_skills or "æ— "}ï¼‰
2. **å¢åŠ å…³é”®è¯å¯†åº¦**ï¼šå·²åŒ¹é…å…³é”®è¯è¦åœ¨ç®€å†ä¸­å‡ºç° 2-3 æ¬¡
3. **é‡åŒ–æˆæœ**ï¼šç”¨æ•°æ®è¯´è¯ï¼ˆå¦‚ï¼šæ€§èƒ½æå‡ X%ã€å¤„ç†é‡ X ä¸‡æ¬¡/æ—¥ï¼‰
4. **ATS å‹å¥½æ ¼å¼**ï¼šé¿å…è¡¨æ ¼ã€å›¾ç‰‡ã€ç‰¹æ®Šç¬¦å·ï¼Œä½¿ç”¨æ ‡å‡†å­—ä½“å’Œæ ‡é¢˜
5. **è‡ªç„¶èå…¥**ï¼šå…³é”®è¯è¦è‡ªç„¶èå…¥å¥å­ï¼Œä¸è¦ç”Ÿç¡¬å †ç Œ

---

**ç°åœ¨å¼€å§‹è¾“å‡ºä¼˜åŒ–å»ºè®®**ï¼ˆä¸è¦ä»»ä½•å¼€åœºç™½ï¼Œç›´æ¥ä»ç¬¬ä¸€æ¡å»ºè®®å¼€å§‹ï¼‰ï¼š"""

        llm_config = {
            "provider": "deepseek",
            "model": "deepseek-chat",
            "mode": "chat",
            "completion_params": {
                "temperature": 0.7,
                "max_tokens": 3000
            }
        }

        # Retry logic for LLM invocation
        max_retries = 3
        retry_delay = 1  # Initial delay in seconds

        for attempt in range(max_retries):
            try:
                llm_result = self.session.model.llm.invoke(
                    model_config=LLMModelConfig(**llm_config),
                    prompt_messages=[UserPromptMessage(content=prompt)],
                    stream=False
                )

                response_text = llm_result.message.content.strip()

                # Check for empty response
                if not response_text:
                    if attempt < max_retries - 1:
                        print(f"âš ï¸ LLM returned empty recommendations (attempt {attempt + 1}/{max_retries}), retrying in {retry_delay}s...")
                        time.sleep(retry_delay)
                        retry_delay *= 2
                        continue
                    else:
                        print(f"âŒ LLM returned empty recommendations after {max_retries} attempts, using fallback")
                        return self._generate_rule_based_recommendations(missing_high, missing_medium, weighted_score)

                return response_text

            except Exception as llm_err:
                if attempt < max_retries - 1:
                    print(f"âš ï¸ LLM recommendation generation failed (attempt {attempt + 1}/{max_retries}): {str(llm_err)}, retrying in {retry_delay}s...")
                    time.sleep(retry_delay)
                    retry_delay *= 2
                    continue
                else:
                    print(f"âŒ LLM recommendation generation failed after {max_retries} attempts, using fallback")
                    return self._generate_rule_based_recommendations(missing_high, missing_medium, weighted_score)

        # Fallback to rule-based recommendations
        return self._generate_rule_based_recommendations(missing_high, missing_medium, weighted_score)

    def _generate_rule_based_recommendations(self, missing_high: list[dict],
                                            missing_medium: list[dict],
                                            weighted_score: float) -> str:
        """Generate rule-based recommendations (when LLM is disabled)"""
        recommendations = []

        recommendations.append(f"## ATS åŒ¹é…åº¦: {weighted_score}%\n")

        if weighted_score >= 80:
            recommendations.append("âœ… **ä¼˜ç§€**ï¼šæ‚¨çš„ç®€å†ä¸èŒä½æè¿°é«˜åº¦åŒ¹é…ï¼")
        elif weighted_score >= 60:
            recommendations.append("âš ï¸ **è‰¯å¥½**ï¼šç®€å†åŒ¹é…åº¦ä¸é”™ï¼Œä½†ä»æœ‰ä¼˜åŒ–ç©ºé—´ã€‚")
        else:
            recommendations.append("âŒ **éœ€è¦ä¼˜åŒ–**ï¼šç®€å†ä¸èŒä½æè¿°åŒ¹é…åº¦è¾ƒä½ï¼Œå»ºè®®é‡ç‚¹ä¼˜åŒ–ã€‚")

        if missing_high:
            recommendations.append("\n### ğŸ”´ é«˜ä¼˜å…ˆçº§ç¼ºå¤±å…³é”®è¯ï¼ˆå¿…é¡»è¡¥å……ï¼‰")
            for s in missing_high[:10]:
                recommendations.append(f"- **{s['skill']}** (JDä¸­å‡ºç°{s['jd_mentions']}æ¬¡)")

        if missing_medium:
            recommendations.append("\n### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ç¼ºå¤±å…³é”®è¯ï¼ˆå»ºè®®è¡¥å……ï¼‰")
            for s in missing_medium[:10]:
                recommendations.append(f"- **{s['skill']}** (JDä¸­å‡ºç°{s['jd_mentions']}æ¬¡)")

        recommendations.append("\n### ğŸ’¡ ä¼˜åŒ–å»ºè®®")
        recommendations.append("1. åœ¨ç®€å†ä¸­è¡¥å……ç¼ºå¤±çš„é«˜ä¼˜å…ˆçº§å…³é”®è¯")
        recommendations.append("2. ç¡®ä¿å…³é”®è¯å‡ºç°åœ¨ç®€å†çš„å¤šä¸ªéƒ¨åˆ†ï¼ˆæŠ€èƒ½ã€é¡¹ç›®ç»éªŒã€å·¥ä½œç»å†ï¼‰")
        recommendations.append("3. ä½¿ç”¨é‡åŒ–æŒ‡æ ‡çªå‡ºå·²åŒ¹é…çš„å…³é”®è¯")
        recommendations.append("4. é¿å…ä½¿ç”¨è¡¨æ ¼ã€å›¾ç‰‡ç­‰ ATS éš¾ä»¥è¯†åˆ«çš„æ ¼å¼")

        return "\n".join(recommendations)

    def _create_summary(self, match_result: dict, has_jd: bool) -> str:
        """Create human-readable summary with Greenhouse-style scoring"""
        if not has_jd:
            resume_kw_count = len(match_result.get('resume_keywords', []))
            return f"""# ğŸ“‹ ç®€å†å…³é”®è¯æå–ç»“æœ

âœ… æˆåŠŸæå– {resume_kw_count} ä¸ªå…³é”®è¯

ğŸ’¡ **æç¤º**: æä¾›èŒä½æè¿°ï¼ˆJDï¼‰å¯ä»¥è·å¾—ï¼š
- Greenhouse/Lever ATS åŒ¹é…åº¦åˆ†æ
- åˆ†çº§å…³é”®è¯åŒ¹é…æƒ…å†µ
- æ™ºèƒ½ä¼˜åŒ–å»ºè®®

è¯·åœ¨å‚æ•°ä¸­æ·»åŠ  `jd_text` æ¥è·å–å®Œæ•´çš„åŒ¹é…åˆ†æã€‚"""

        # New Greenhouse analysis
        greenhouse = match_result['greenhouse_analysis']
        match_details = match_result['match_details']
        optimization = match_result['optimization_suggestions']
        legacy = match_result['legacy_scores']

        greenhouse_score = greenhouse['greenhouse_score']
        status = greenhouse['status']

        # Score emoji based on Greenhouse score
        if greenhouse_score >= 85:
            score_emoji = "ğŸŸ¢"
        elif greenhouse_score >= 75:
            score_emoji = "ğŸŸ¡"
        elif greenhouse_score >= 65:
            score_emoji = "ğŸŸ "
        else:
            score_emoji = "ğŸ”´"

        summary_lines = [
            "# ğŸ¯ ATS åŒ¹é…åˆ†æï¼ˆGreenhouse/Lever æ¨¡æ‹Ÿï¼‰",
            "",
            f"## {score_emoji} Greenhouse é¢„ä¼°åˆ†æ•°: {greenhouse_score} åˆ†",
            "",
            greenhouse['recommendation'],
            "",
            "---",
            "",
            "## ğŸ“Š åˆ†çº§åŒ¹é…æƒ…å†µ",
            "",
            f"### ğŸ”´ å¿…éœ€æŠ€èƒ½ï¼ˆMust-haveï¼‰",
            f"- åŒ¹é…: {greenhouse['must_have_match']} ({greenhouse['must_have_rate']}%)",
        ]

        # Show must-have details
        must_have_matched = [s for s in match_details['must_have'] if s['matched']]
        must_have_missing = [s for s in match_details['must_have'] if not s['matched']]

        if must_have_matched:
            summary_lines.append("- å·²åŒ¹é…: " + ", ".join([f"**{s['skill']}**" for s in must_have_matched]))
        if must_have_missing:
            summary_lines.append("- âŒ ç¼ºå¤±: " + ", ".join([f"**{s['skill']}**" for s in must_have_missing]))

        summary_lines.extend([
            "",
            f"### ğŸŸ¡ é«˜ä¼˜å…ˆçº§æŠ€èƒ½ï¼ˆHigh Priorityï¼‰",
            f"- åŒ¹é…: {greenhouse['high_priority_match']} ({greenhouse['high_priority_rate']}%)",
        ])

        # Show high priority details
        high_matched = [s for s in match_details['high_priority'] if s['matched']]
        high_missing = [s for s in match_details['high_priority'] if not s['matched']]

        if high_matched:
            summary_lines.append("- å·²åŒ¹é…: " + ", ".join([f"**{s['skill']}**" for s in high_matched[:5]]))
        if high_missing:
            summary_lines.append("- âŒ ç¼ºå¤±: " + ", ".join([f"**{s['skill']}**" for s in high_missing[:5]]))

        summary_lines.extend([
            "",
            f"### ğŸŸ¢ ä¸­ä¼˜å…ˆçº§æŠ€èƒ½ï¼ˆMedium Priorityï¼‰",
            f"- åŒ¹é…: {greenhouse['medium_priority_match']} ({greenhouse['medium_priority_rate']}%)",
            "",
            f"### âšª åŠ åˆ†é¡¹ï¼ˆNice-to-haveï¼‰",
            f"- åŒ¹é…: {greenhouse['nice_to_have_match']} ({greenhouse['nice_to_have_rate']}%)",
            "",
            "---",
            "",
            "## ğŸ’¡ ä¼˜åŒ–å»ºè®®",
            "",
            optimization,
            "",
            "---",
            "",
            "## ğŸ“ˆ è¯„åˆ†å¯¹æ¯”",
            "",
            f"- **Greenhouse åˆ†æ•°**: {greenhouse_score} åˆ†ï¼ˆæ¨¡æ‹Ÿ Greenhouse/Lever ATSï¼‰",
            f"- **ä¼ ç»ŸåŠ æƒåˆ†æ•°**: {legacy['weighted_score']}% ï¼ˆåŸºäºå…³é”®è¯é¢‘ç‡ï¼‰",
            f"- **ç®€å•åŒ¹é…ç‡**: {legacy['simple_score']}% ï¼ˆ{legacy['matched_keywords']}/{legacy['total_keywords']}ï¼‰",
            "",
            "ğŸ’¡ **è¯´æ˜**: Greenhouse åˆ†æ•°æ›´æ¥è¿‘çœŸå® ATS ç³»ç»Ÿçš„è¯„åˆ†é€»è¾‘ï¼Œä¼˜å…ˆè€ƒè™‘å¿…éœ€æŠ€èƒ½å’Œé«˜ä¼˜å…ˆçº§æŠ€èƒ½ã€‚",
        ])

        return "\n".join(summary_lines)

    def _parse_resume_keywords_input(self, input_str: str) -> list[dict[str, Any]] | None:
        """
        Intelligently parse resume_keywords input from various formats.

        Supports:
        1. JSON array: [{"skill": "Python", "mentions": 3, ...}, ...]
        2. JSON object: {"keywords": [...], ...}
        3. Text summary from keyword_extraction tool (parse keywords from markdown)

        Args:
            input_str: Input string from user

        Returns:
            List of keyword dicts, or None if parsing fails
        """
        input_str = input_str.strip()

        # Try 1: Parse as JSON
        try:
            parsed = json.loads(input_str)

            if isinstance(parsed, list):
                # Direct array: [{"skill": "Python", ...}, ...]
                return parsed
            elif isinstance(parsed, dict) and 'keywords' in parsed:
                # Full result object: {"keywords": [...], ...}
                return parsed['keywords']
        except json.JSONDecodeError:
            pass

        # Try 2: Parse as text summary from keyword_extraction
        # Look for patterns like: "- **Python** (2 mentions) - explicit mention"
        keywords = []

        # Pattern 1: "- **Skill** (N mentions) - source"
        pattern1 = r'-\s+\*\*([^*]+)\*\*\s+\((\d+)\s+mentions?\)\s+-\s+(.+)'
        matches1 = re.findall(pattern1, input_str)
        for skill, mentions, source in matches1:
            keywords.append({
                "skill": skill.strip(),
                "mentions": int(mentions),
                "confidence": 1.0,
                "source": "parsed_from_text"
            })

        # Pattern 2: "- **Skill** - description"
        pattern2 = r'-\s+\*\*([^*]+)\*\*\s+-\s+(.+)'
        matches2 = re.findall(pattern2, input_str)
        for skill, description in matches2:
            # Skip if already matched by pattern1
            if not any(k['skill'] == skill.strip() for k in keywords):
                keywords.append({
                    "skill": skill.strip(),
                    "mentions": 1,
                    "confidence": 0.8,
                    "source": "parsed_from_text"
                })

        if keywords:
            return keywords

        # Parsing failed
        return None

    def _generate_standard_jd_requirements(self, position_name: str) -> str:
        """
        Use LLM to generate standard job requirements for a given position name.

        Args:
            position_name: Job position name (e.g., "ç®—æ³•å·¥ç¨‹å¸ˆå®ä¹ ", "å‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆ")

        Returns:
            Generated job description text with standard requirements
        """
        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ HR å’Œæ‹›è˜ä¸“å®¶ã€‚è¯·ä¸º"{position_name}"è¿™ä¸ªèŒä½ç”Ÿæˆæ ‡å‡†çš„æŠ€èƒ½è¦æ±‚æ¸…å•ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

# {position_name} - æ ‡å‡†èŒä½è¦æ±‚

## æ ¸å¿ƒæŠ€èƒ½è¦æ±‚ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
åˆ—å‡º 3-5 ä¸ªå¿…é¡»æŒæ¡çš„æ ¸å¿ƒæŠ€èƒ½ï¼Œæ¯ä¸ªæŠ€èƒ½éœ€è¦åœ¨æè¿°ä¸­å‡ºç° 3 æ¬¡ä»¥ä¸Šã€‚

## é‡è¦æŠ€èƒ½è¦æ±‚ï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰
åˆ—å‡º 5-8 ä¸ªå»ºè®®æŒæ¡çš„é‡è¦æŠ€èƒ½ï¼Œæ¯ä¸ªæŠ€èƒ½éœ€è¦åœ¨æè¿°ä¸­å‡ºç° 2 æ¬¡ã€‚

## åŠ åˆ†æŠ€èƒ½è¦æ±‚ï¼ˆä½ä¼˜å…ˆçº§ï¼‰
åˆ—å‡º 3-5 ä¸ªåŠ åˆ†é¡¹æŠ€èƒ½ï¼Œæ¯ä¸ªæŠ€èƒ½å‡ºç° 1 æ¬¡å³å¯ã€‚

## èŒä½æè¿°
ç”¨ 2-3 æ®µè¯æè¿°è¿™ä¸ªèŒä½çš„å·¥ä½œå†…å®¹å’ŒèŒè´£ï¼Œè‡ªç„¶åœ°èå…¥ä¸Šè¿°æŠ€èƒ½å…³é”®è¯ã€‚

æ³¨æ„ï¼š
1. æŠ€èƒ½å…³é”®è¯è¦å…·ä½“ï¼ˆä¾‹å¦‚ï¼šPythonã€TensorFlowã€RAGï¼Œè€Œä¸æ˜¯"ç¼–ç¨‹èƒ½åŠ›"ã€"å­¦ä¹ èƒ½åŠ›"ï¼‰
2. æ ¹æ®èŒä½çº§åˆ«è°ƒæ•´è¦æ±‚ï¼ˆå®ä¹ ç”Ÿ vs é«˜çº§å·¥ç¨‹å¸ˆï¼‰
3. ç¡®ä¿å…³é”®è¯åœ¨æè¿°ä¸­è‡ªç„¶å‡ºç°æŒ‡å®šæ¬¡æ•°
4. ä½¿ç”¨ä¸­æ–‡è¾“å‡º

è¯·å¼€å§‹ç”Ÿæˆï¼š"""

        llm_config = {
            "provider": "deepseek",
            "model": "deepseek-chat",
            "mode": "chat",
            "completion_params": {
                "temperature": 0.7,
                "max_tokens": 2000
            }
        }

        # Retry logic for LLM invocation
        max_retries = 3
        retry_delay = 1  # Initial delay in seconds

        for attempt in range(max_retries):
            try:
                llm_result = self.session.model.llm.invoke(
                    model_config=LLMModelConfig(**llm_config),
                    prompt_messages=[UserPromptMessage(content=prompt)],
                    stream=False
                )

                response_text = llm_result.message.content.strip()

                # Check for empty response
                if not response_text:
                    if attempt < max_retries - 1:
                        print(f"âš ï¸ LLM returned empty JD (attempt {attempt + 1}/{max_retries}), retrying in {retry_delay}s...")
                        time.sleep(retry_delay)
                        retry_delay *= 2
                        continue
                    else:
                        print(f"âŒ LLM returned empty JD after {max_retries} attempts, using fallback")
                        return f"""# {position_name} - æ ‡å‡†èŒä½è¦æ±‚

## æ ¸å¿ƒæŠ€èƒ½è¦æ±‚
æ ¹æ®èŒä½åç§°ï¼Œè¯·æä¾›å®Œæ•´çš„èŒä½æè¿°ä»¥è·å¾—æ›´å‡†ç¡®çš„åŒ¹é…åˆ†æã€‚

LLM ç”Ÿæˆå¤±è´¥: å¤šæ¬¡é‡è¯•åä»è¿”å›ç©ºå“åº”
"""

                return response_text

            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"âš ï¸ LLM JD generation failed (attempt {attempt + 1}/{max_retries}): {str(e)}, retrying in {retry_delay}s...")
                    time.sleep(retry_delay)
                    retry_delay *= 2
                    continue
                else:
                    print(f"âŒ LLM JD generation failed after {max_retries} attempts: {str(e)}")
                    return f"""# {position_name} - æ ‡å‡†èŒä½è¦æ±‚

## æ ¸å¿ƒæŠ€èƒ½è¦æ±‚
æ ¹æ®èŒä½åç§°ï¼Œè¯·æä¾›å®Œæ•´çš„èŒä½æè¿°ä»¥è·å¾—æ›´å‡†ç¡®çš„åŒ¹é…åˆ†æã€‚

LLM ç”Ÿæˆå¤±è´¥: {str(e)}
"""

        # Fallback
        return f"""# {position_name} - æ ‡å‡†èŒä½è¦æ±‚

## æ ¸å¿ƒæŠ€èƒ½è¦æ±‚
æ ¹æ®èŒä½åç§°ï¼Œè¯·æä¾›å®Œæ•´çš„èŒä½æè¿°ä»¥è·å¾—æ›´å‡†ç¡®çš„åŒ¹é…åˆ†æã€‚

LLM ç”Ÿæˆå¤±è´¥: æœªçŸ¥é”™è¯¯
"""

    def _extract_keywords_from_generated_jd(self, generated_jd: str) -> list[dict[str, Any]]:
        """
        Extract keywords from LLM-generated job description.
        Parse the structured output and create keyword list with priorities.

        Args:
            generated_jd: LLM-generated job description text

        Returns:
            List of keyword dictionaries with skill, mentions, priority, weight
        """
        keywords = []

        # Parse high-priority skills (mentioned 3+ times in the generated JD)
        high_priority_pattern = r"## æ ¸å¿ƒæŠ€èƒ½è¦æ±‚[^#]+"
        high_match = re.search(high_priority_pattern, generated_jd, re.DOTALL)
        if high_match:
            high_section = high_match.group(0)
            # Extract skill names (look for technical terms in Chinese/English)
            skills = re.findall(r'[A-Za-z][A-Za-z0-9+#\.]*(?:\.[A-Za-z]+)?', high_section)
            for skill in skills:
                if len(skill) > 1:  # Filter out single letters
                    keywords.append({
                        "skill": skill,
                        "mentions": 3,  # High priority = 3 mentions
                        "confidence": 1.0,
                        "source": "llm_generated",
                        "priority": "high",
                        "weight": 3.0
                    })

        # Parse medium-priority skills (mentioned 2 times)
        medium_priority_pattern = r"## é‡è¦æŠ€èƒ½è¦æ±‚[^#]+"
        medium_match = re.search(medium_priority_pattern, generated_jd, re.DOTALL)
        if medium_match:
            medium_section = medium_match.group(0)
            skills = re.findall(r'[A-Za-z][A-Za-z0-9+#\.]*(?:\.[A-Za-z]+)?', medium_section)
            for skill in skills:
                if len(skill) > 1 and skill not in [k['skill'] for k in keywords]:
                    keywords.append({
                        "skill": skill,
                        "mentions": 2,  # Medium priority = 2 mentions
                        "confidence": 1.0,
                        "source": "llm_generated",
                        "priority": "medium",
                        "weight": 2.0
                    })

        # Parse low-priority skills (mentioned 1 time)
        low_priority_pattern = r"## åŠ åˆ†æŠ€èƒ½è¦æ±‚[^#]+"
        low_match = re.search(low_priority_pattern, generated_jd, re.DOTALL)
        if low_match:
            low_section = low_match.group(0)
            skills = re.findall(r'[A-Za-z][A-Za-z0-9+#\.]*(?:\.[A-Za-z]+)?', low_section)
            for skill in skills:
                if len(skill) > 1 and skill not in [k['skill'] for k in keywords]:
                    keywords.append({
                        "skill": skill,
                        "mentions": 1,  # Low priority = 1 mention
                        "confidence": 1.0,
                        "source": "llm_generated",
                        "priority": "low",
                        "weight": 1.0
                    })

        return keywords

