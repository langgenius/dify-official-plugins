from typing import Any
from collections.abc import Generator

from dify_plugin import Tool
from dify_plugin.entities.tool import ToolInvokeMessage
from dify_plugin.entities.model.llm import LLMModelConfig
from dify_plugin.entities.model.message import UserPromptMessage


class ResumeOptimizerTool(Tool):
    """
    Resume optimization tool with bilingual support and target position integration.

    This tool helps users optimize their resumes for specific job positions using LLM.
    It supports both file upload and text input, with bilingual prompts.
    """

    PROMPTS = {
        "zh_Hans": """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç®€å†ä¼˜åŒ–ä¸“å®¶ã€‚è¯·é’ˆå¯¹ã€{target_position}ã€‘å²—ä½ï¼Œç›´æ¥ç»™å‡ºå…·ä½“çš„ä¿®æ”¹å»ºè®®ã€‚

ç›®æ ‡å²—ä½ï¼š{target_position}

{detected_issues_section}

## è¾“å‡ºè¦æ±‚

**ä¸è¦**è‡ªæˆ‘ä»‹ç»ã€ä¸è¦åˆ†æé—®é¢˜ã€ä¸è¦ä»‹ç»å·¥ä½œè®¡åˆ’ï¼Œ**ç›´æ¥å¼€å§‹è¾“å‡ºä¼˜åŒ–å»ºè®®**ã€‚

æŒ‰ç…§ç®€å†çš„å®é™…æ¨¡å—ç»“æ„ï¼ˆå¦‚ï¼šæ•™è‚²èƒŒæ™¯ã€å·¥ä½œç»å†ã€é¡¹ç›®ç»éªŒã€ä¸“ä¸šæŠ€èƒ½ç­‰ï¼‰ï¼Œé€ä¸€ç»™å‡ºä¼˜åŒ–å»ºè®®ã€‚

æ¯æ¡å»ºè®®å¿…é¡»åŒ…å«ï¼š
- **æ”¹å‰**ï¼šä»ç®€å†ä¸­æ‘˜å½•éœ€è¦ä¿®æ”¹çš„åŸæ–‡ï¼ˆä¿æŒåŸæ–‡æ ¼å¼ï¼‰
- **æ”¹å**ï¼šä¼˜åŒ–åçš„è¡¨è¿°ï¼ˆå¯ç›´æ¥å¤åˆ¶ç²˜è´´ä½¿ç”¨ï¼‰
- **ä¼˜åŒ–ç†ç”±**ï¼š1-2 å¥è¯è¯´æ˜ä¸ºä»€ä¹ˆè¿™æ ·æ”¹æ›´é€‚åˆã€{target_position}ã€‘å²—ä½

## è¾“å‡ºæ ¼å¼

### ğŸ“‹ [æ¨¡å—åç§°]

**æ”¹å‰**ï¼š
```
[ä»ç®€å†ä¸­æ‘˜å½•çš„åŸæ–‡]
```

**æ”¹å**ï¼š
```
[ä¼˜åŒ–åçš„è¡¨è¿°]
```

**ä¼˜åŒ–ç†ç”±**ï¼š[ç®€æ´è¯´æ˜]

---

### ğŸ“‹ [ä¸‹ä¸€ä¸ªæ¨¡å—åç§°]

**æ”¹å‰**ï¼š
```
[åŸæ–‡]
```

**æ”¹å**ï¼š
```
[ä¼˜åŒ–åçš„è¡¨è¿°]
```

**ä¼˜åŒ–ç†ç”±**ï¼š[ç®€æ´è¯´æ˜]

---

{issues_fix_section}

## ä¼˜åŒ–é‡ç‚¹

1. **å…³é”®è¯åŒ¹é…**ï¼šç¡®ä¿ç®€å†åŒ…å«ã€{target_position}ã€‘å²—ä½çš„æ ¸å¿ƒæŠ€æœ¯æ ˆå’Œå…³é”®è¯
2. **é‡åŒ–æˆæœ**ï¼šç”¨æ•°æ®è¯´è¯ï¼ˆå¦‚ï¼šæ€§èƒ½æå‡ X%ã€å¤„ç†é‡ X ä¸‡æ¬¡/æ—¥ï¼‰
3. **åŠ¨ä½œåŠ¨è¯**ï¼šä½¿ç”¨"è®¾è®¡ã€å®ç°ã€ä¼˜åŒ–ã€è´Ÿè´£"ç­‰å¼ºåŠ¨ä½œè¯ï¼Œé¿å…"å‚ä¸ã€äº†è§£"
4. **å²—ä½ç›¸å…³æ€§**ï¼šçªå‡ºä¸ç›®æ ‡å²—ä½æœ€ç›¸å…³çš„ç»éªŒï¼Œå¼±åŒ–æ— å…³å†…å®¹
5. **STAR æ³•åˆ™**ï¼šSituationï¼ˆèƒŒæ™¯ï¼‰â†’ Taskï¼ˆä»»åŠ¡ï¼‰â†’ Actionï¼ˆè¡ŒåŠ¨ï¼‰â†’ Resultï¼ˆç»“æœï¼‰

## æ³¨æ„äº‹é¡¹

- åªé’ˆå¯¹**éœ€è¦ä¼˜åŒ–çš„å†…å®¹**ç»™å‡ºå»ºè®®ï¼Œå·²ç»å¾ˆå¥½çš„éƒ¨åˆ†å¯ä»¥è·³è¿‡
- æ¯æ¡å»ºè®®éƒ½è¦**å…·ä½“ã€å¯æ“ä½œ**ï¼Œç”¨æˆ·å¯ä»¥ç›´æ¥å¤åˆ¶ç²˜è´´
- ä¿æŒç®€å†çš„**åŸæœ‰ç»“æ„å’Œé£æ ¼**ï¼Œä¸è¦å¤§å¹…æ”¹å˜æ’ç‰ˆ
- å¦‚æœç®€å†ä¸­æŸäº›æ¨¡å—ç¼ºå¤±ä½†å¯¹ç›®æ ‡å²—ä½é‡è¦ï¼Œå¯ä»¥å»ºè®®æ·»åŠ 

---

**ç°åœ¨å¼€å§‹è¾“å‡ºä¼˜åŒ–å»ºè®®**ï¼ˆä¸è¦ä»»ä½•å¼€åœºç™½ï¼Œç›´æ¥ä»ç¬¬ä¸€ä¸ªæ¨¡å—å¼€å§‹ï¼‰ï¼š

ç®€å†å†…å®¹ï¼š
{resume_content}""",

        "en_US": """You are a seasoned resume optimization expert. Please provide specific modification suggestions for the [{target_position}] position.

Target Position: {target_position}

{detected_issues_section}

## Output Requirements

**Do NOT** introduce yourself, analyze problems, or describe your work plan. **Start directly with optimization suggestions**.

Provide suggestions for each actual section in the resume (e.g., Education, Work Experience, Projects, Skills, etc.).

Each suggestion must include:
- **Before**: Original text from the resume (keep original format)
- **After**: Optimized version (ready to copy-paste)
- **Reason**: 1-2 sentences explaining why this change better fits the [{target_position}] position

## Output Format

### ğŸ“‹ [Section Name]

**Before**:
```
[Original text from resume]
```

**After**:
```
[Optimized version]
```

**Reason**: [Brief explanation]

---

### ğŸ“‹ [Next Section Name]

**Before**:
```
[Original text]
```

**After**:
```
[Optimized version]
```

**Reason**: [Brief explanation]

---

{issues_fix_section}

## Optimization Focus

1. **Keyword Matching**: Ensure resume includes core tech stack and keywords for [{target_position}]
2. **Quantified Achievements**: Use data (e.g., improved performance by X%, handled X requests/day)
3. **Action Verbs**: Use strong verbs like "designed, implemented, optimized, led" instead of "participated, familiar with"
4. **Job Relevance**: Highlight most relevant experience for target position, de-emphasize irrelevant content
5. **STAR Method**: Situation â†’ Task â†’ Action â†’ Result

## Guidelines

- Only provide suggestions for **content that needs improvement**; skip parts that are already good
- Each suggestion should be **specific and actionable**, ready to copy-paste
- Maintain the **original structure and style** of the resume, don't drastically change layout
- If important sections are missing for the target position, suggest adding them

---

**Start outputting optimization suggestions now** (no introduction, start directly from the first section):

Resume Content:
{resume_content}"""
    }

    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage]:
        """
        Invoke the resume optimizer tool.

        Args:
            tool_parameters: Tool parameters including resume_content, target_position, detected_issues, and language

        Returns:
            Generator of ToolInvokeMessage
        """
        try:
            # Extract and validate parameters
            target_position = tool_parameters.get('target_position', '').strip()
            detected_issues = tool_parameters.get('detected_issues', '').strip()
            language = tool_parameters.get('language', 'zh_Hans')

            # Get resume content from file upload or text input
            resume_content, error_msg = self._get_resume_content(tool_parameters, language)
            if error_msg:
                yield self.create_text_message(error_msg)
                return

            # Validate required parameters
            if not target_position:
                error_msg = "ç›®æ ‡å²—ä½ä¸èƒ½ä¸ºç©º" if language == 'zh_Hans' else "Target position cannot be empty"
                yield self.create_text_message(error_msg)
                return

            # Generate optimization suggestions using LLM
            result = self._optimize_resume_with_llm(resume_content, target_position, detected_issues, language)
            yield self.create_text_message(result)

        except Exception as e:
            error_msg = f"ä¼˜åŒ–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}" if language == 'zh_Hans' else f"Error during optimization: {str(e)}"
            yield self.create_text_message(error_msg)

    def _get_resume_content(self, tool_parameters: dict[str, Any], language: str) -> tuple[str, str]:
        """
        Extract resume content from text input.

        Returns:
            tuple: (resume_content, error_message)
        """
        # Get resume content from text input
        resume_content = tool_parameters.get('resume_content', '').strip()
        if not resume_content:
            error_msg = "è¯·è¾“å…¥ç®€å†å†…å®¹" if language == 'zh_Hans' else "Please input resume content"
            return "", error_msg

        return resume_content, ""

    def _optimize_resume_with_llm(self, resume_content: str, target_position: str, detected_issues: str, language: str) -> str:
        """Use LLM to generate resume optimization suggestions."""
        try:
            # Build detected issues section
            detected_issues_section = ""
            issues_fix_section = ""

            if detected_issues:
                if language == 'zh_Hans':
                    detected_issues_section = f"## å·²æ£€æµ‹åˆ°çš„é—®é¢˜\n\n{detected_issues}\n"
                    issues_fix_section = "\n5. **é—®é¢˜ä¿®å¤** - é’ˆå¯¹ä¸Šè¿°æ£€æµ‹åˆ°çš„é—®é¢˜æä¾›å…·ä½“ä¿®å¤å»ºè®®"
                else:
                    detected_issues_section = f"## Detected Issues\n\n{detected_issues}\n"
                    issues_fix_section = "\n5. **Issue Resolution** - Specific fixes for the detected issues above"

            # Build prompt using template
            prompt_template = self.PROMPTS.get(language, self.PROMPTS['zh_Hans'])
            prompt = prompt_template.format(
                target_position=target_position,
                resume_content=resume_content,
                detected_issues_section=detected_issues_section,
                issues_fix_section=issues_fix_section
            )

            # Prepare LLM request
            prompt_messages = [UserPromptMessage(content=prompt)]

            # Use system-configured LLM (user should configure DeepSeek in Dify settings)
            # This approach follows Dify's best practices for plugin LLM usage
            llm_config = {
                "provider": "deepseek",
                "model": "deepseek-chat",
                "mode": "chat",
                "completion_params": {
                    "temperature": 0.7,
                    "max_tokens": 2000
                }
            }

            # Invoke LLM
            llm_result = self.session.model.llm.invoke(
                model_config=LLMModelConfig(**llm_config),
                prompt_messages=prompt_messages,
                stream=False
            )

            # Extract result
            if llm_result and hasattr(llm_result, 'message') and hasattr(llm_result.message, 'content'):
                return llm_result.message.content
            else:
                return "LLMè°ƒç”¨è¿”å›ç©ºç»“æœ" if language == 'zh_Hans' else "LLM returned empty result"

        except Exception as e:
            error_details = str(e)
            if "Provider" in error_details and "does not exist" in error_details:
                return f"è¯·åœ¨Difyè®¾ç½®ä¸­é…ç½®DeepSeekæä¾›å•†: {error_details}" if language == 'zh_Hans' else f"Please configure DeepSeek provider in Dify settings: {error_details}"
            else:
                return f"LLMè°ƒç”¨å¤±è´¥: {error_details}" if language == 'zh_Hans' else f"LLM invocation failed: {error_details}"
