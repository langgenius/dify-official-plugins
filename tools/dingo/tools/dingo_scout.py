"""
Dingo Scout - Strategic Job Hunting Module

v1.0.0 - Initial Release

Features:
1. Natural language user profile parsing
2. Industry report analysis (company extraction, financial signals)
3. Person-job fit scoring algorithm with sub-scores
4. Search strategy generation
5. Interview style prediction
6. Grounding: All conclusions require source quotes

Algorithm:
- Score = weighted sum of (skill_match, risk_alignment, career_stage_fit, location_match, financial_health)
- Tier 1: match_score >= 0.75
- Tier 2: match_score >= 0.50
- Not Recommended: match_score < 0.50 or financial_status = "contraction"
"""

import json
import os
import time
from typing import Any
from collections.abc import Generator

from dify_plugin import Tool
from dify_plugin.entities.tool import ToolInvokeMessage
from dify_plugin.entities.model.llm import LLMModelConfig
from dify_plugin.entities.model.message import SystemPromptMessage, UserPromptMessage


# ============================================================================
# SYSTEM PROMPT - Core LLM Analysis Logic
# ============================================================================

SCOUT_SYSTEM_PROMPT = """ä½ æ˜¯ Dingo Scoutï¼Œä¸€ä½ä¸“ä¸šçš„æ±‚èŒæˆ˜ç•¥åˆ†æå¸ˆã€‚
ä½ çš„ä»»åŠ¡æ˜¯ä»å¤æ‚çš„è¡Œä¸šæŠ¥å‘Šä¸­æå–å¯¹æ±‚èŒè€…æœ‰ä»·å€¼çš„ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆç²¾å‡†çš„æ±‚èŒæˆ˜ç•¥ã€‚

## é‡è¦è§„åˆ™

1. **ç¦æ­¢ä½¿ç”¨ä»»ä½• Emoji ç¬¦å·**ã€‚è¾“å‡ºå¿…é¡»æ˜¯çº¯æ–‡æœ¬ã€‚
2. **åªåˆ†ææŠ¥å‘Šä¸­æ˜ç¡®æåŠçš„å…¬å¸**ï¼Œä¸è¦æ¨æµ‹æœªæåŠçš„å…¬å¸ã€‚
3. **æ‰€æœ‰è´¢åŠ¡åˆ¤æ–­å¿…é¡»é™„å¸¦åŸæ–‡å¼•ç”¨ (Grounding)**ã€‚
4. å¦‚æœæŠ¥å‘Šä¸­åªæœ‰"ç‰‡æ±¤è¯"è€Œæ— å…·ä½“æ•°æ®ï¼Œè¾“å‡º confidence < 0.5ã€‚

---

## 1. ç”¨æˆ·ç”»åƒè§£æ (User Profile Parsing)

**è¾“å…¥æ ¼å¼**:
- user_profile: è‡ªç„¶è¯­è¨€æˆ– JSONï¼ˆå¿…éœ€ï¼‰
- resume_text: å®Œæ•´ç®€å†æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰

**è§£æç­–ç•¥**:

**æƒ…å†µ A - åŒæ—¶æä¾› resume_text å’Œ user_profile**:
1. ä» resume_text æå–è¯¦ç»†æŠ€èƒ½åˆ—è¡¨ï¼ˆç¡¬æŠ€èƒ½ï¼šç¼–ç¨‹è¯­è¨€ã€æ¡†æ¶ã€å·¥å…·ï¼‰
2. ä» resume_text æå–é¡¹ç›®ç»éªŒå’Œå·¥ä½œå¹´é™
3. ä» user_profile æå–åå¥½ä¿¡æ¯ï¼ˆåœ°ç‚¹ã€é£é™©åå¥½ã€è–ªèµ„é¢„æœŸç­‰è½¯åå¥½ï¼‰
4. åˆå¹¶åç”¨äº scoring_breakdown.skill_match è®¡ç®—ï¼Œæå‡åŒ¹é…ç²¾åº¦
5. ä¸éœ€è¦è¾“å‡ºé¢å¤–å­—æ®µï¼Œä»…è®©è¯„åˆ†æ›´å‡†ç¡®

**æƒ…å†µ B - ä»…æä¾› user_profile**:
æŒ‰ä»¥ä¸‹è§„åˆ™ä»è‡ªç„¶è¯­è¨€ä¸­æå–æ‰€æœ‰ä¿¡æ¯ã€‚

**è‡ªç„¶è¯­è¨€ç¤ºä¾‹**:
"æˆ‘æ˜¯23å±Šçš„CSç¡•å£«ï¼Œåœ¨å­—èŠ‚åšè¿‡å¤§æ¨¡å‹åº”ç”¨å®ä¹ ï¼Œä¼šPythonå’ŒPyTorchï¼Œæƒ³æ‰¾ä¸ªå¤§å‚ï¼Œæœ€å¥½åœ¨åŒ—äº¬ã€‚"

**è§£æè§„åˆ™**:

| ç»´åº¦ | æå–æ–¹æ³• | é»˜è®¤å€¼ |
|------|----------|--------|
| å­¦å† | "ç¡•å£«/Master" -> Master, "æœ¬ç§‘/Bachelor" -> Bachelor | Bachelor |
| ä¸“ä¸š | "CS/è®¡ç®—æœº/è½¯ä»¶" -> CS, "EE/ç”µå­" -> EE | CS |
| ç»éªŒå¹´é™ | "å®ä¹ " -> 0-1å¹´, "3å¹´ç»éªŒ" -> 3å¹´ | 0 |
| æŠ€æœ¯æ ˆ | æå–æ‰€æœ‰æŠ€æœ¯å…³é”®è¯ | [] |
| é£é™©åå¥½ | "å¤§å‚/ç¨³å®š" -> conservative, "åˆ›ä¸šå…¬å¸" -> aggressive | moderate |
| èŒä¸šé˜¶æ®µ | "åº”å±Š/23å±Š" -> new_grad, "3å¹´" -> junior | new_grad |
| åœ°ç‚¹åå¥½ | æå–åŸå¸‚å | [] |

**æ¨¡ç³Šæ¨æ–­**:
- "æƒ³æ‰¾å¤§å‚" -> risk_preference = conservative
- "ä¸ä»‹æ„åŠ ç­" -> å¯æ¥å—é«˜å¼ºåº¦æ–‡åŒ–
- "æœ‰å¥³æœ‹å‹åœ¨ä¸Šæµ·" -> location_preference = ["ä¸Šæµ·"]

---

## 2. æŠ¥å‘Šä¿¡æ¯æå–ä¸ Grounding

### 2.1 å…¬å¸åˆ—è¡¨æå–
æå–æ‰€æœ‰è¢«æåŠçš„å…¬å¸åç§°ï¼ˆåŒ…æ‹¬ç®€ç§°ã€å…¨ç§°ã€è‹±æ–‡åï¼‰ã€‚

### 2.2 è´¢åŠ¡ä¿¡å·åˆ†ç±»

**Expansion (æ‰©å¼ )**: ROE ä¸Šå‡ã€ä¸»åŠ›èµ„é‡‘å‡€æµå…¥ã€æ–°ä¸šåŠ¡çº¿ã€æ‰©æ‹›ä¿¡å·
**Stable (ç¨³å¥)**: ROE å¹³ç¨³ã€èµ„é‡‘æµå¹³è¡¡ã€ä¸šåŠ¡ç»´æŠ¤æœŸ
**Contraction (æ”¶ç¼©)**: ROE ä¸‹é™ã€èµ„é‡‘æµå‡ºã€è£å‘˜ä¼ é—»ã€ä¸šåŠ¡æ”¶ç¼©
**Uncertain**: å­˜åœ¨çŸ›ç›¾ä¿¡å·ï¼ˆå¦‚è¥æ”¶å¢ä½†åˆ©æ¶¦é™ï¼‰
**Unknown**: æŠ¥å‘Šä¸­æ— è¯¥å…¬å¸çš„å…·ä½“è´¢åŠ¡æ•°æ®

### 2.3 Grounding è§„åˆ™ (å…³é”®!)

**æ‰€æœ‰è´¢åŠ¡åˆ¤æ–­å¿…é¡»é™„å¸¦åŸæ–‡å¼•ç”¨**:

```json
"financial_evidence": {
  "source_quotes": [
    "è±†åŒ…å•†ä¸šåŒ–åŠ é€Ÿï¼ŒAI è½åœ°å›¢é˜Ÿæ‰©ç¼– 30%ï¼ˆæŠ¥å‘Šç¬¬3æ®µï¼‰",
    "ROE åŒæ¯”ä¸Šå‡ 15%ï¼ˆæŠ¥å‘Šç¬¬1æ®µï¼‰"
  ],
  "confidence": 0.9,
  "conflicting_signals": null
}
```

**å¦‚æœå­˜åœ¨çŸ›ç›¾ä¿¡å·**:
```json
"financial_evidence": {
  "source_quotes": [
    "è¥æ”¶åŒæ¯”å¢é•¿ 20%ï¼ˆæŠ¥å‘Šç¬¬2æ®µï¼‰",
    "ä½†å‡€åˆ©æ¶¦ä¸‹æ»‘ 15%ï¼ˆæŠ¥å‘Šç¬¬4æ®µï¼‰"
  ],
  "confidence": 0.5,
  "conflicting_signals": "è¥æ”¶å¢é•¿ä½†åˆ©æ¶¦ä¸‹æ»‘ï¼Œæ‰©å¼ å¯æŒç»­æ€§å­˜ç–‘"
}
```

**æœ‰æ•ˆè¯æ® vs æ— æ•ˆè¯æ®**:

| æœ‰æ•ˆè¯æ® | æ— æ•ˆè¯æ® |
|----------|----------|
| "ROE ä¸Šå‡ 15%" | "æˆ‘ä»¬è‡´åŠ›äºåˆ›æ–°" |
| "èµ„é‡‘å‡€æµå…¥ 50 äº¿" | "æœªæ¥å¯æœŸ" |
| "å›¢é˜Ÿæ‰©ç¼– 30%" | "è¡Œä¸šé¢†å…ˆåœ°ä½" |
| "è£å‘˜ 2000 äºº" | "ä¼˜åŒ–ç»„ç»‡æ¶æ„" |

**ç¦æ­¢è¡Œä¸º**:
1. ç¦æ­¢å°† A å…¬å¸çš„æ•°æ®ç”¨äº B å…¬å¸çš„åˆ¤æ–­
2. ç¦æ­¢ä»"ç‰‡æ±¤è¯"ä¸­æ¨æ–­è´¢åŠ¡çŠ¶æ€
3. å¦‚æœåªæœ‰æ— æ•ˆè¯æ®ï¼Œå¿…é¡»è¾“å‡º confidence < 0.5

---

## 3. äººå²—åŒ¹é…é€»è¾‘

### Tier 1 (æ ¸å¿ƒç›®æ ‡) - åŒæ—¶æ»¡è¶³:
1. æŠ€èƒ½åŒ¹é…åº¦ >= 70%
2. é£é™©åå¥½åŒ¹é… (conservative -> å¤§å‚, aggressive -> å¯æ¥å—åˆ›ä¸š)
3. è´¢åŠ¡çŠ¶æ€ä¸º expansion æˆ– stable
4. è¯æ®ç½®ä¿¡åº¦ >= 0.7

### Tier 2 (æ½œåœ¨æœºä¼š) - æ»¡è¶³ä»»ä¸€:
1. æŠ€èƒ½åŒ¹é…åº¦ 50-70%ï¼Œä½†å…¬å¸ expansion
2. æŠ€èƒ½åŒ¹é…åº¦ >= 70%ï¼Œä½†å…¬å¸ stableï¼ˆæˆé•¿ç©ºé—´æœ‰é™ï¼‰
3. å­˜åœ¨çŸ›ç›¾ä¿¡å· (conflicting_signals)

### Insufficient Data (æ•°æ®ä¸è¶³) - æ»¡è¶³å…¨éƒ¨:
1. æŠ¥å‘Šä¸­æœªæä¾›è¯¥å…¬å¸çš„å…·ä½“è´¢åŠ¡æ•°æ®ï¼ˆfinancial_status = unknownï¼‰
2. ä½†è¯¥å…¬å¸å±äºè¡Œä¸šå…¬è®¤é¾™å¤´æˆ–å¤§å‚ï¼ˆå¦‚ BATã€å­—èŠ‚ã€ç¾å›¢ã€åä¸ºç­‰ï¼‰
3. æŠ€èƒ½åŒ¹é…åº¦ >= 50%

**å¤„ç†æ–¹å¼**: æ”¾å…¥ `insufficient_data` åˆ—è¡¨ï¼Œå»ºè®®ç”¨æˆ·è‡ªè¡Œæœç´¢è¯¥å…¬å¸æœ€æ–°è´¢æŠ¥ã€‚
**ä¸è¦æ”¾å…¥ Not Recommendedï¼**

### Not Recommended - æ»¡è¶³ä»»ä¸€:
1. å…¬å¸ contractionï¼ˆæœ‰æ˜ç¡®æ”¶ç¼©è¯æ®ï¼‰
2. æŠ€èƒ½åŒ¹é…åº¦ < 50%
3. è¯æ®ç½®ä¿¡åº¦ < 0.5 ä¸”å…¬å¸éè¡Œä¸šé¾™å¤´

---

## 4. è¯„åˆ†ç»´åº¦ (scoring_breakdown)

è¯·ä¸ºæ¯ä¸ªå…¬å¸è¾“å‡ºä»¥ä¸‹å­åˆ†æ•°ï¼Œç³»ç»Ÿå°†åŠ æƒè®¡ç®—æ€»åˆ†ï¼š

```json
"scoring_breakdown": {
  "skill_match": {
    "score": 0.0-1.0,
    "matched_skills": ["Python", "PyTorch"],
    "missing_skills": ["Go"],
    "reasoning": "ç”¨æˆ· LLM ç»éªŒä¸ AI è½åœ°éœ€æ±‚åŒ¹é…"
  },
  "risk_alignment": {
    "score": 0.0-1.0,
    "user_preference": "conservative",
    "company_risk_level": "low",
    "reasoning": "å¤§å‚ + æ‰©å¼ æœŸï¼Œç¬¦åˆç¨³å®šåå¥½"
  },
  "career_stage_fit": {
    "score": 0.0-1.0,
    "user_stage": "new_grad",
    "company_fit": "æœ‰å®Œå–„åŸ¹å…»ä½“ç³»",
    "reasoning": "å­—èŠ‚æœ‰æˆç†Ÿçš„æ–°äººåŸ¹å…»æœºåˆ¶"
  },
  "location_match": {
    "score": 0.0-1.0,
    "user_preference": ["åŒ—äº¬", "ä¸Šæµ·"],
    "company_locations": ["åŒ—äº¬"],
    "reasoning": "å®Œå…¨åŒ¹é…"
  },
  "financial_health": {
    "score": 0.0-1.0,
    "status": "expansion",
    "reasoning": "ROEä¸Šå‡ï¼Œèµ„é‡‘å……è£•"
  }
}
```

---

## 5. è¾“å‡ºæ ¼å¼

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON ç»“æ„è¾“å‡ºï¼š

```json
{
  "strategy_context": {
    "target_companies": [
      {
        "name": "å…¬å¸åç§°",
        "financial_status": "expansion|stable|contraction|uncertain|unknown",
        "financial_evidence": {
          "source_quotes": ["åŸæ–‡å¼•ç”¨1", "åŸæ–‡å¼•ç”¨2"],
          "confidence": 0.0-1.0,
          "conflicting_signals": "çŸ›ç›¾è¯´æ˜æˆ–null"
        },
        "scoring_breakdown": { ... },
        "match_reasoning": "ä¸ºä»€ä¹ˆåŒ¹é…ï¼ˆ50å­—ä»¥å†…ï¼‰",
        "hiring_trigger": "å…·ä½“çš„æ‰©æ‹›åŸå› ",
        "search_keywords": ["å…³é”®è¯1", "å…³é”®è¯2"],
        "recommended_platforms": ["Bossç›´è˜", "æ‹‰å‹¾"],
        "interview_style": "é¢è¯•é£æ ¼æè¿°",
        "interview_prep_tips": [
          "ç®—æ³•: å…·ä½“å»ºè®®",
          "ç³»ç»Ÿè®¾è®¡: å…·ä½“å»ºè®®",
          "é¡¹ç›®: å…·ä½“å»ºè®®"
        ],
        "salary_leverage": "è–ªèµ„è°ˆåˆ¤ç­¹ç åˆ†æ",
        "culture_fit": "æ–‡åŒ–åŒ¹é…åº¦åˆ†æ",
        "timing_advice": "æœ€ä½³æŠ•é€’æ—¶æœº"
      }
    ],
    "insufficient_data": [
      {
        "name": "å…¬å¸åç§°ï¼ˆè¡Œä¸šé¾™å¤´ä½†æŠ¥å‘Šæ— å…·ä½“æ•°æ®ï¼‰",
        "reason": "æŠ¥å‘Šä¸­ç¼ºä¹è¯¥å…¬å¸çš„å…·ä½“è´¢åŠ¡æ•°æ®",
        "available_info": ["è¡Œä¸šåœ°ä½æè¿°ç­‰éé‡åŒ–ä¿¡æ¯"],
        "suggestion": "å»ºè®®è‡ªè¡Œæœç´¢è¯¥å…¬å¸æœ€æ–°è´¢æŠ¥"
      }
    ],
    "not_recommended": [
      {
        "name": "å…¬å¸åç§°",
        "reason": "ä¸æ¨èåŸå› ï¼ˆéœ€æœ‰æ˜ç¡®æ”¶ç¼©è¯æ®æˆ–æŠ€èƒ½ä¸¥é‡ä¸åŒ¹é…ï¼‰"
      }
    ],
    "meta": {
      "report_date": "ä»æŠ¥å‘Šä¸­æå–æˆ–å¡«ä»Šå¤©æ—¥æœŸ",
      "analysis_confidence": 0.0-1.0,
      "user_profile_summary": "ç”¨æˆ·ç”»åƒæ‘˜è¦ï¼ˆå¦‚ï¼š23å±ŠCSç¡•å£«ï¼ŒLLMç»éªŒï¼Œconservativeï¼‰"
    }
  }
}
```

---

ç°åœ¨ï¼Œè¯·åˆ†æç”¨æˆ·æä¾›çš„è¡Œä¸šæŠ¥å‘Šå’Œç”¨æˆ·ç”»åƒï¼Œç”Ÿæˆæˆ˜ç•¥ä¸Šä¸‹æ–‡å¡ç‰‡ã€‚
"""


class SchemaValidationError(Exception):
    """Custom exception for schema validation failures."""
    pass


class DingoScout(Tool):
    """
    Strategic job hunting module that analyzes industry reports
    and user profiles to generate targeted recommendations.
    """

    # Scoring weights (configurable)
    SCORE_WEIGHTS = {
        "skill_match": 0.40,
        "risk_alignment": 0.20,
        "career_stage_fit": 0.15,
        "location_match": 0.10,
        "financial_health": 0.15
    }

    # Tier thresholds
    TIER_THRESHOLDS = {
        "tier1": 0.75,
        "tier2": 0.50
    }

    # Confidence thresholds
    CONFIDENCE_THRESHOLDS = {
        "tier1_min": 0.7,
        "tier2_min": 0.5,
        "insufficient": 0.5
    }

    MAX_RETRIES = 2

    # Company URL data cache
    _company_urls: dict = None

    # ========================================================================
    # Company URL Loading
    # ========================================================================

    def _load_company_urls(self) -> dict:
        """
        Load company recruitment URLs from JSON data file.
        Returns empty dict if file not found or parse error.
        """
        if DingoScout._company_urls is not None:
            return DingoScout._company_urls

        try:
            # Get path relative to this script: ../data/company_urls.json
            current_dir = os.path.dirname(os.path.abspath(__file__))
            data_path = os.path.join(current_dir, '..', 'data', 'company_urls.json')
            data_path = os.path.normpath(data_path)

            with open(data_path, 'r', encoding='utf-8') as f:
                DingoScout._company_urls = json.load(f)
                print(f"[Scout] Loaded {len(DingoScout._company_urls)} company URLs")
                return DingoScout._company_urls

        except FileNotFoundError:
            print(f"[Scout] company_urls.json not found, skipping URL injection")
            DingoScout._company_urls = {}
            return {}
        except json.JSONDecodeError as e:
            print(f"[Scout] Failed to parse company_urls.json: {e}")
            DingoScout._company_urls = {}
            return {}
        except Exception as e:
            print(f"[Scout] Error loading company URLs: {e}")
            DingoScout._company_urls = {}
            return {}

    def _inject_urls(self, companies: list) -> None:
        """
        Inject recruitment URLs into company data.
        Uses exact match on company name (full name or short name).
        """
        url_map = self._load_company_urls()
        if not url_map:
            return

        for company in companies:
            name = company.get("name", "")
            if not name:
                continue

            # Exact match lookup
            url = url_map.get(name)
            if url:
                company["recruitment_url"] = url

    # ========================================================================
    # Main Entry Point
    # ========================================================================

    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage]:
        """
        Main entry point for Dingo Scout.

        Args:
            tool_parameters:
                - industry_report (str): Raw industry/financial report text
                - user_profile (str): Natural language or JSON user profile
                - resume_text (str, optional): Full resume text for skill extraction
                - output_format (str): 'markdown' | 'json'

        Returns:
            - JSON message: strategy_context
            - Text message: Human-readable strategy card (if markdown)
        """
        try:
            industry_report = tool_parameters.get('industry_report', '').strip()
            user_profile = tool_parameters.get('user_profile', '').strip()
            resume_text = tool_parameters.get('resume_text', '').strip()
            output_format = tool_parameters.get('output_format', 'markdown')

            # Validation
            if not industry_report:
                yield self.create_text_message("[Error] è¯·æä¾›è¡Œä¸šæŠ¥å‘Š")
                return

            if not user_profile:
                yield self.create_text_message("[Error] è¯·æä¾›ç”¨æˆ·ç”»åƒ")
                return

            # Build user prompt with optional resume
            if resume_text:
                user_content = f"""### è¡Œä¸šæŠ¥å‘Š:
{industry_report}

### ç”¨æˆ·ç”»åƒ:
{user_profile}

### ä¸ªäººç®€å† (ç”¨äºæŠ€èƒ½æå–ï¼Œæå‡åŒ¹é…ç²¾åº¦):
{resume_text}

è¯·åˆ†æå¹¶è¾“å‡ºæˆ˜ç•¥ä¸Šä¸‹æ–‡å¡ç‰‡ (JSON æ ¼å¼)ã€‚
æ³¨æ„ï¼šå·²æä¾›ç®€å†ï¼Œè¯·ä»ä¸­æå–æŠ€èƒ½åˆ—è¡¨ç”¨äº skill_match è¯„åˆ†è®¡ç®—ã€‚"""
            else:
                user_content = f"""### è¡Œä¸šæŠ¥å‘Š:
{industry_report}

### ç”¨æˆ·ç”»åƒ:
{user_profile}

è¯·åˆ†æå¹¶è¾“å‡ºæˆ˜ç•¥ä¸Šä¸‹æ–‡å¡ç‰‡ (JSON æ ¼å¼)ã€‚"""

            # Invoke LLM with retry
            try:
                raw_result = self._invoke_llm_with_retry(
                    system_prompt=SCOUT_SYSTEM_PROMPT,
                    user_content=user_content
                )
            except Exception as e:
                yield self.create_text_message(
                    f"[Warning] LLM åˆ†æå¤±è´¥: {str(e)}\n\n"
                    "å»ºè®®:\n"
                    "1. æ£€æŸ¥è¡Œä¸šæŠ¥å‘Šæ˜¯å¦åŒ…å«å…·ä½“å…¬å¸å’Œè´¢åŠ¡æ•°æ®\n"
                    "2. å°è¯•ç®€åŒ–æŠ¥å‘Šå†…å®¹åé‡è¯•\n"
                    "3. æ‰‹åŠ¨æå–å…³é”®å…¬å¸ä¿¡æ¯"
                )
                return

            # Apply safe defaults
            result = self._safe_parse_with_defaults(raw_result)

            # Calculate scores and filter by confidence
            result = self._process_llm_result(result)

            # Output
            yield self.create_json_message(result)

            if output_format == 'json':
                json_str = json.dumps(result, ensure_ascii=False, indent=2)
                yield self.create_text_message(json_str)
            else:
                summary = self._create_markdown_summary(result)
                yield self.create_text_message(summary)

        except Exception as e:
            import traceback
            print(f"[Scout] Unexpected error: {traceback.format_exc()}")
            yield self.create_text_message(f"[Error] æˆ˜ç•¥åˆ†æå¤±è´¥: {str(e)}")

    # ========================================================================
    # LLM Invocation with Retry
    # ========================================================================

    def _get_llm_config(self) -> dict:
        """Get LLM configuration."""
        return {
            "provider": "deepseek",
            "model": "deepseek-chat",
            "mode": "chat",
            "completion_params": {
                "temperature": 0.3,
                "max_tokens": 6000
            }
        }

    def _invoke_llm_with_retry(
        self,
        system_prompt: str,
        user_content: str
    ) -> dict:
        """
        Invoke LLM with retry mechanism for JSON parsing.
        On failure, sends error message back to LLM for correction.
        """
        last_error = None
        last_response = None

        for attempt in range(self.MAX_RETRIES + 1):
            try:
                # Build prompt
                if attempt == 0:
                    current_prompt = user_content
                else:
                    current_prompt = self._build_retry_prompt(
                        original_request=user_content,
                        last_response=last_response,
                        error_message=str(last_error)
                    )

                # Call LLM with streaming to avoid TTFB timeout
                response_generator = self.session.model.llm.invoke(
                    model_config=LLMModelConfig(**self._get_llm_config()),
                    prompt_messages=[
                        SystemPromptMessage(content=system_prompt),
                        UserPromptMessage(content=current_prompt)
                    ],
                    stream=True
                )

                # Collect all chunks into complete response
                collected_content = []
                for chunk in response_generator:
                    try:
                        if content := chunk.delta.message.content:
                            collected_content.append(content)
                    except AttributeError:
                        # Skip chunks that don't have the expected .delta.message.content structure
                        continue

                last_response = "".join(collected_content).strip()

                # Try to parse JSON
                result = self._parse_json_response(last_response)

                # Validate schema
                self._validate_schema(result)

                return result

            except json.JSONDecodeError as e:
                last_error = f"JSON è§£æå¤±è´¥: {str(e)}"
                print(f"[Scout] Attempt {attempt + 1} failed: {last_error}")
                if attempt < self.MAX_RETRIES:
                    time.sleep(1)

            except SchemaValidationError as e:
                last_error = f"Schema æ ¡éªŒå¤±è´¥: {str(e)}"
                print(f"[Scout] Attempt {attempt + 1} failed: {last_error}")
                if attempt < self.MAX_RETRIES:
                    time.sleep(1)

            except Exception as e:
                last_error = str(e)
                print(f"[Scout] Attempt {attempt + 1} failed: {last_error}")
                if attempt < self.MAX_RETRIES:
                    time.sleep(1)

        raise Exception(f"LLM è¾“å‡ºè§£æå¤±è´¥ï¼Œå·²é‡è¯• {self.MAX_RETRIES} æ¬¡: {last_error}")

    def _build_retry_prompt(
        self,
        original_request: str,
        last_response: str,
        error_message: str
    ) -> str:
        """Build retry prompt with error feedback."""
        return f"""ä½ ä¸Šä¸€æ¬¡çš„è¾“å‡ºæœ‰æ ¼å¼é—®é¢˜ï¼Œè¯·ä¿®æ­£ã€‚

## é”™è¯¯ä¿¡æ¯
{error_message}

## ä½ ä¸Šæ¬¡çš„è¾“å‡º (æœ‰é—®é¢˜)
```
{last_response[:2000]}...
```

## åŸå§‹è¯·æ±‚
{original_request}

## ä¿®æ­£è¦æ±‚
1. ç¡®ä¿è¾“å‡ºæ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼
2. ç¡®ä¿æ‰€æœ‰å­—ç¬¦ä¸²ä½¿ç”¨åŒå¼•å·
3. ç¡®ä¿ target_companies æ˜¯ä¸€ä¸ªæ•°ç»„
4. ç¡®ä¿æ¯ä¸ªå…¬å¸éƒ½æœ‰ name, financial_status, financial_evidence å­—æ®µ

è¯·é‡æ–°è¾“å‡ºæ­£ç¡®çš„ JSONã€‚
"""

    # ========================================================================
    # JSON Parsing and Validation
    # ========================================================================

    def _parse_json_response(self, response_text: str) -> dict:
        """Extract and parse JSON from LLM response."""
        text = response_text.strip()

        # Remove markdown code blocks
        if text.startswith("```json"):
            text = text[7:]
        elif text.startswith("```"):
            text = text[3:]
        if text.endswith("```"):
            text = text[:-3]

        # Find JSON boundaries
        start = text.find('{')
        end = text.rfind('}')
        if start != -1 and end != -1:
            text = text[start:end+1]

        return json.loads(text.strip())

    def _validate_schema(self, data: dict) -> None:
        """
        Validate LLM output against expected schema.
        Raises SchemaValidationError if validation fails.
        """
        errors = []

        if "strategy_context" not in data:
            errors.append("ç¼ºå°‘ strategy_context å­—æ®µ")
        else:
            context = data["strategy_context"]

            # Check target_companies
            if "target_companies" not in context:
                errors.append("ç¼ºå°‘ target_companies å­—æ®µ")
            elif not isinstance(context["target_companies"], list):
                errors.append("target_companies å¿…é¡»æ˜¯æ•°ç»„")
            else:
                for i, company in enumerate(context["target_companies"]):
                    company_errors = self._validate_company(company, i)
                    errors.extend(company_errors)

            # Check meta
            if "meta" not in context:
                errors.append("ç¼ºå°‘ meta å­—æ®µ")

        if errors:
            raise SchemaValidationError("\n".join(errors))

    def _validate_company(self, company: dict, index: int) -> list[str]:
        """Validate a single company object."""
        errors = []
        prefix = f"target_companies[{index}]"

        if "name" not in company:
            errors.append(f"{prefix}: ç¼ºå°‘ name å­—æ®µ")

        if "financial_status" not in company:
            errors.append(f"{prefix}: ç¼ºå°‘ financial_status å­—æ®µ")
        elif company["financial_status"] not in ["expansion", "stable", "contraction", "uncertain", "unknown"]:
            errors.append(f"{prefix}: financial_status å€¼æ— æ•ˆ: {company['financial_status']}")

        return errors


    # ========================================================================
    # Score Calculation and Result Processing
    # ========================================================================

    def _safe_parse_with_defaults(self, data: dict) -> dict:
        """Apply safe defaults for missing optional fields."""
        context = data.get("strategy_context", {})

        for company in context.get("target_companies", []):
            company.setdefault("tier", None)
            company.setdefault("match_score", None)
            company.setdefault("search_keywords", [])
            company.setdefault("recommended_platforms", ["Bossç›´è˜"])
            company.setdefault("interview_style", "å¾…ç¡®è®¤")
            company.setdefault("interview_prep_tips", [])
            company.setdefault("salary_leverage", "å¾…åˆ†æ")
            company.setdefault("culture_fit", "å¾…åˆ†æ")
            company.setdefault("financial_evidence", {
                "source_quotes": [],
                "confidence": 0.5,
                "conflicting_signals": None
            })
            company.setdefault("scoring_breakdown", {})

        context.setdefault("not_recommended", [])
        meta = context.setdefault("meta", {})
        meta.setdefault("analysis_confidence", 0.5)
        meta.setdefault("report_date", "æœªçŸ¥")
        meta.setdefault("user_profile_summary", "")

        return data

    def _calculate_match_score(self, scoring_breakdown: dict) -> tuple[float, str]:
        """
        Calculate weighted match score from LLM sub-scores.
        Returns: (match_score, tier)
        """
        total_score = 0.0
        total_weight = 0.0

        for dimension, weight in self.SCORE_WEIGHTS.items():
            if dimension in scoring_breakdown:
                sub_score = scoring_breakdown[dimension].get("score", 0.0)
                if sub_score is not None:
                    total_score += sub_score * weight
                    total_weight += weight

        if total_weight > 0:
            match_score = round(total_score / total_weight, 2)
        else:
            match_score = 0.5  # Default when no scoring data

        # Determine tier
        if match_score >= self.TIER_THRESHOLDS["tier1"]:
            tier = "Tier 1"
        elif match_score >= self.TIER_THRESHOLDS["tier2"]:
            tier = "Tier 2"
        else:
            tier = "Not Recommended"

        return match_score, tier

    def _filter_by_confidence(self, companies: list) -> tuple[list, list, list]:
        """
        Filter companies by financial evidence confidence.
        Returns: (qualified, insufficient_data, not_recommended)
        """
        qualified = []
        insufficient = []
        not_recommended = []

        for company in companies:
            evidence = company.get("financial_evidence", {})
            confidence = evidence.get("confidence", 0.0)
            status = company.get("financial_status", "unknown")

            # Contraction: directly exclude
            if status == "contraction":
                quotes = evidence.get("source_quotes", ["æ— "])
                quote_preview = quotes[0][:50] if quotes else "æ— "
                not_recommended.append({
                    "name": company["name"],
                    "reason": f"è´¢åŠ¡æ”¶ç¼©æœŸ (è¯æ®: {quote_preview}...)"
                })
                continue

            # Low confidence: insufficient data
            if confidence < self.CONFIDENCE_THRESHOLDS["insufficient"]:
                insufficient.append({
                    "name": company["name"],
                    "reason": "æŠ¥å‘Šä¸­ç¼ºä¹è¯¥å…¬å¸çš„å…·ä½“è´¢åŠ¡æ•°æ®",
                    "available_info": evidence.get("source_quotes", []),
                    "suggestion": "å»ºè®®è‡ªè¡Œæœç´¢è¯¥å…¬å¸æœ€æ–°è´¢æŠ¥æˆ–æ‹›è˜åŠ¨æ€"
                })
                continue

            # Conflicting signals: downgrade to Tier 2
            if evidence.get("conflicting_signals"):
                company["tier"] = "Tier 2"
                company["risk_warning"] = evidence["conflicting_signals"]

            qualified.append(company)

        return qualified, insufficient, not_recommended

    def _process_llm_result(self, llm_data: dict) -> dict:
        """Post-process LLM output with score calculation and confidence filtering."""
        context = llm_data.get("strategy_context", {})
        companies = context.get("target_companies", [])

        # 1. Calculate scores for each company
        for company in companies:
            scoring = company.get("scoring_breakdown", {})
            if scoring:
                match_score, tier = self._calculate_match_score(scoring)
                company["match_score"] = match_score
                company["tier"] = tier
            else:
                # Use LLM-provided score if no breakdown
                if company.get("match_score") is None:
                    company["match_score"] = 0.5
                if company.get("tier") is None:
                    company["tier"] = "Tier 2"

        # 2. Inject recruitment URLs
        self._inject_urls(companies)

        # 3. Filter by confidence
        qualified, insufficient, llm_not_recommended = self._filter_by_confidence(companies)

        # 4. Merge with LLM's not_recommended
        all_not_recommended = llm_not_recommended + context.get("not_recommended", [])

        # 5. Sort by score
        qualified.sort(key=lambda x: x.get("match_score", 0), reverse=True)

        return {
            "strategy_context": {
                "target_companies": qualified,
                "insufficient_data": insufficient,
                "not_recommended": all_not_recommended,
                "meta": context.get("meta", {})
            }
        }


    # ========================================================================
    # Markdown Output Generation
    # ========================================================================

    def _create_markdown_summary(self, result: dict) -> str:
        """Create human-readable markdown summary."""
        lines = [
            "# Dingo Scout æˆ˜ç•¥åˆ†ææŠ¥å‘Š",
            "",
            "> åŸºäºæ‚¨æä¾›çš„è¡Œä¸šæŠ¥å‘Šå’Œä¸ªäººç”»åƒï¼Œä¸ºæ‚¨ç”Ÿæˆä»¥ä¸‹æ±‚èŒæˆ˜ç•¥å»ºè®®ã€‚",
            "",
            "---",
            "",
        ]

        context = result.get("strategy_context", {})
        target_companies = context.get("target_companies", [])
        insufficient_data = context.get("insufficient_data", [])
        not_recommended = context.get("not_recommended", [])
        meta = context.get("meta", {})

        # Tier 1 & Tier 2 companies
        tier1 = [c for c in target_companies if c.get("tier") == "Tier 1"]
        tier2 = [c for c in target_companies if c.get("tier") == "Tier 2"]

        if tier1:
            lines.append("## [Tier 1] æ ¸å¿ƒç›®æ ‡å…¬å¸")
            lines.append("")
            for i, company in enumerate(tier1, 1):
                lines.extend(self._format_company(i, company))

        if tier2:
            lines.append("## [Tier 2] æ½œåœ¨æœºä¼š")
            lines.append("")
            for i, company in enumerate(tier2, 1):
                lines.extend(self._format_company(i, company))

        if insufficient_data:
            lines.append("## [Insufficient Data] æ•°æ®ä¸è¶³")
            lines.append("")
            lines.append("ä»¥ä¸‹å…¬å¸åœ¨æŠ¥å‘Šä¸­ç¼ºä¹å…·ä½“è´¢åŠ¡æ•°æ®ï¼Œå»ºè®®è‡ªè¡Œæœç´¢ï¼š")
            lines.append("")
            lines.append("| å…¬å¸ | åŸå›  | å»ºè®® |")
            lines.append("|------|------|------|")
            for item in insufficient_data:
                lines.append(f"| {item.get('name', '')} | {item.get('reason', '')} | {item.get('suggestion', '')} |")
            lines.append("")

        if not_recommended:
            lines.append("## [Not Recommended] ä¸æ¨èå…¬å¸")
            lines.append("")
            lines.append("| å…¬å¸ | åŸå›  |")
            lines.append("|------|------|")
            for item in not_recommended:
                lines.append(f"| {item.get('name', '')} | {item.get('reason', '')} |")
            lines.append("")

        # Action items
        if tier1:
            top_company = tier1[0]
            keywords = top_company.get("search_keywords", [""])
            platforms = top_company.get("recommended_platforms", ["Bossç›´è˜"])

            lines.extend([
                "---",
                "",
                "## [Action] ä¸‹ä¸€æ­¥è¡ŒåŠ¨",
                "",
                f"1. å‰å¾€ {', '.join(platforms[:2])} æœç´¢ \"{top_company.get('name', '')} + {keywords[0] if keywords else ''}\"",
                "2. æ‰¾åˆ°çœŸå® JD åï¼Œå¤åˆ¶ JD æ–‡æœ¬",
                "3. ä½¿ç”¨ Dingo Keyword Matcher åˆ†æåŒ¹é…åº¦",
                "4. ä½¿ç”¨ Dingo Resume Optimizer ä¼˜åŒ–ç®€å†ï¼ˆè®°å¾—ä¼ å…¥æœ¬æˆ˜ç•¥å¡ç‰‡ï¼‰",
                "",
            ])

        # Footer
        confidence_pct = int(meta.get('analysis_confidence', 0) * 100)
        lines.extend([
            "---",
            "",
            f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {meta.get('report_date', 'N/A')} | åˆ†æç½®ä¿¡åº¦: {confidence_pct}%",
            f"ç”¨æˆ·ç”»åƒæ‘˜è¦: {meta.get('user_profile_summary', 'N/A')}",
        ])

        return "\n".join(lines)

    def _format_company(self, index: int, company: dict) -> list[str]:
        """Format a single company section."""
        score_pct = int(company.get('match_score', 0) * 100)
        evidence = company.get('financial_evidence', {})
        confidence_pct = int(evidence.get('confidence', 0) * 100)

        lines = [
            f"### {index}. {company.get('name', 'Unknown')}",
        ]

        # Recruitment URL (if available)
        if company.get('recruitment_url'):
            lines.append(f"ğŸ”— [å®˜æ–¹æ‹›è˜å…¥å£]({company.get('recruitment_url')})")

        lines.append(f"**åŒ¹é…åº¦**: {score_pct}% | **ç½®ä¿¡åº¦**: {confidence_pct}%")
        lines.append("")

        # Match reasoning
        if company.get('match_reasoning'):
            lines.append(f"**ä¸ºä»€ä¹ˆæ¨è**: {company.get('match_reasoning')}")
            lines.append("")

        # Financial status with evidence
        lines.append(f"**è´¢åŠ¡çŠ¶æ€**: [{company.get('financial_status', 'unknown')}]")
        if company.get('hiring_trigger'):
            lines.append(f"- {company.get('hiring_trigger')}")

        # Evidence chain
        source_quotes = evidence.get('source_quotes', [])
        if source_quotes:
            lines.append("")
            lines.append("**è¯æ®é“¾**:")
            for quote in source_quotes[:3]:
                lines.append(f"> {quote}")

        # Risk warning
        if company.get('risk_warning'):
            lines.append("")
            lines.append(f"**é£é™©æç¤º**: {company.get('risk_warning')}")

        lines.append("")

        # Search strategy
        lines.append("**æœç´¢ç­–ç•¥**:")
        keywords = company.get('search_keywords', [])
        platforms = company.get('recommended_platforms', [])
        lines.append(f"- å…³é”®è¯: {', '.join(keywords) if keywords else 'å¾…ç¡®è®¤'}")
        lines.append(f"- æ¨èå¹³å°: {', '.join(platforms) if platforms else 'Bossç›´è˜'}")
        if company.get('timing_advice'):
            lines.append(f"- æœ€ä½³æ—¶æœº: {company.get('timing_advice')}")
        lines.append("")

        # Interview prep
        prep_tips = company.get('interview_prep_tips', [])
        if prep_tips:
            lines.append("**é¢è¯•å‡†å¤‡**:")
            for tip in prep_tips:
                lines.append(f"- {tip}")
            lines.append("")

        # Salary and culture
        lines.append(f"**è–ªèµ„è°ˆåˆ¤**: {company.get('salary_leverage', 'å¾…åˆ†æ')}")
        lines.append("")
        lines.append(f"**æ–‡åŒ–åŒ¹é…**: {company.get('culture_fit', 'å¾…åˆ†æ')}")
        lines.append("")
        lines.append("---")
        lines.append("")

        return lines
